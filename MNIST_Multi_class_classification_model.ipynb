{"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Justus-coded/DPhi-Deep-Learning-Bootcamp/blob/master/MNIST_Multi_class_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text","cell_id":"00000-d549519d-1a6b-4569-a2e5-f525bbb6cbf0"}},{"cell_type":"markdown","source":"# Introduction\nIn this notebook we will build a Neural Network multi-class classification model using a dataset popularly known as **'MNIST'**\n\n","metadata":{"id":"X-XphER4SWG6","colab_type":"text","cell_id":"00001-18f5dedb-e53d-4721-8267-79b077aa4ddd"}},{"cell_type":"markdown","source":"# Agenda\n*  About the Data\n*  Loading Libraries\n*  Loading Data\n*  Basic EDA\n*  Data Preprocessing\n*  Model Building\n  *  Simple Neural Network With No Hidden Layer\n  *  Building Model Using Hidden Layer\n*  Summary","metadata":{"id":"hcWWIvw2RxlS","colab_type":"text","cell_id":"00002-4de27a28-661d-481d-8477-1bdf9952679c"}},{"cell_type":"markdown","source":"## About the Data\n**MNIST (Modified National Institute of Standards and Technology database)** is a large database of 70,000 handwritten digits. \n\nIt has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST (National Institute of Standards and Technology).\n\nThe objective here is to build a model that would recognize the correct digit that the given image is representing.\n\n","metadata":{"id":"a3x9Y9moS5fY","colab_type":"text","cell_id":"00003-000f311c-abad-4d23-9d80-2d98799cd336"}},{"cell_type":"markdown","source":"## Objective\nIn this notebook we will classify handwritten digits using a simple neural network which has only input and output layers. We will then add a hidden layer and see how the performance of the model improves","metadata":{"id":"_8udR2dR1CAm","colab_type":"text","cell_id":"00004-a2e6a9c4-f9a3-4cdd-85b1-bab8a5f6731e"}},{"cell_type":"markdown","source":"## Loading Libraries\nAll Python capabilities are not loaded to our working environment by default (even if they are already installed in your system). So, we import each and every library that we want to use. Sometimes we chose alias names for our libraries for the sake of our convenience for example we **import tensorflow as tf** and similarly the other libraries\n","metadata":{"id":"y06TLJHMU_5x","colab_type":"text","cell_id":"00005-d667598b-fa2a-4f8c-921d-3e4fd2ebab2c"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-a077d6f9-1417-44ca-a4e7-956364c1fb95"},"source":"#pip install tensorflow\n","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting tensorflow\n  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n\u001b[K     |████████████████████████████████| 320.4 MB 19 kB/s s eta 0:00:01��▋               | 165.8 MB 38.2 MB/s eta 0:00:05��▉               | 168.0 MB 38.2 MB/s eta 0:00:04��█████████████▋              | 176.7 MB 38.2 MB/s eta 0:00:04\n\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n\u001b[K     |████████████████████████████████| 459 kB 23.8 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta>=0.1.8\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 4.4 MB/s  eta 0:00:01\n\u001b[?25hCollecting tensorboard<3,>=2.3.0\n  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n\u001b[K     |████████████████████████████████| 6.8 MB 35.3 MB/s eta 0:00:01\n\u001b[?25hCollecting absl-py>=0.7.0\n  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 32.6 MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.9.2\n  Downloading protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 31.3 MB/s eta 0:00:01\n\u001b[?25hCollecting wrapt>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting termcolor>=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nRequirement already satisfied: wheel>=0.26 in /opt/venv/lib/python3.7/site-packages (from tensorflow) (0.34.2)\nCollecting scipy==1.4.1\n  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n\u001b[K     |████████████████████████████████| 26.1 MB 110 kB/s  eta 0:00:01\n\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 44.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/venv/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nCollecting keras-preprocessing<1.2,>=1.1.1\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 12 kB/s s eta 0:00:01\n\u001b[?25hCollecting astunparse==1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 108 kB/s  eta 0:00:01B/s eta 0:00:01\n\u001b[?25hCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 211 kB/s  eta 0:00:01\n\u001b[?25hCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nCollecting grpcio>=1.8.6\n  Downloading grpcio-1.31.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n\u001b[K     |████████████████████████████████| 3.4 MB 26.3 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n\u001b[K     |████████████████████████████████| 779 kB 34.0 MB/s eta 0:00:01\n\u001b[?25hCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 35.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/venv/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (47.3.1)\nCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.21.0-py2.py3-none-any.whl (92 kB)\n\u001b[K     |████████████████████████████████| 92 kB 1.0 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/venv/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n\u001b[K     |████████████████████████████████| 88 kB 7.3 MB/s  eta 0:00:01\n\u001b[?25hCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\nCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n\u001b[K     |████████████████████████████████| 47 kB 4.6 MB/s  eta 0:00:01\n\u001b[?25hCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 44.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n\u001b[K     |████████████████████████████████| 147 kB 42.8 MB/s eta 0:00:01\n\u001b[?25hCollecting pyasn1>=0.1.3\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 4.7 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\nBuilding wheels for collected packages: wrapt, termcolor\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71569 sha256=e7f0ce3ecfecfdc2d4f508517a2dc42fb1dabe10c0e4b45cc6a72604bf228996\n  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=7312a68b593c8222204510200e076291ae4ff114c30181e832f6450a9242148c\n  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\nSuccessfully built wrapt termcolor\nInstalling collected packages: tensorflow-estimator, google-pasta, grpcio, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, numpy, tensorboard-plugin-wit, werkzeug, absl-py, protobuf, markdown, tensorboard, wrapt, termcolor, scipy, h5py, keras-preprocessing, astunparse, opt-einsum, gast, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.0\n    Uninstalling numpy-1.19.0:\n      Successfully uninstalled numpy-1.19.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.5.1\n    Uninstalling scipy-1.5.1:\n      Successfully uninstalled scipy-1.5.1\nSuccessfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.21.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"n6IzyeUHFlId","colab_type":"code","colab":{},"cell_id":"00006-71fd0522-9cad-4714-a31a-6afd8768121f"},"source":"import tensorflow as tf                       # deep learning library\nimport numpy as np                            # for matrix operations\nimport matplotlib.pyplot as plt               # for visualization\n%matplotlib inline","execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data\nThe MNIST dataset is available in the TensorFlow only. Let's load the data:","metadata":{"id":"Ph7HLzWTFlIr","colab_type":"text","cell_id":"00007-805b6039-28a5-41da-9db8-a815036fe85f"}},{"cell_type":"code","metadata":{"id":"ubTJHv0xFlIr","colab_type":"code","colab":{},"cell_id":"00008-ca87fe99-fac3-4fc5-985e-d28787f7d146"},"source":"from tensorflow.keras.datasets.mnist import load_data    # To load the MNIST digit dataset\n\n(X_train, y_train) , (X_test, y_test) = load_data()      # Loading data","execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Basic EDA","metadata":{"id":"sGVmx0ra2QLt","colab_type":"text","cell_id":"00009-1c4b6c8f-93a1-4fc6-a7cb-a16ca8cb3da4"}},{"cell_type":"code","metadata":{"id":"m6WviKsE2Ism","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"83c42917-14d1-4c03-9043-aa200dc90ea6","cell_id":"00010-be51fa3a-51a9-4ea2-8a84-11e02bb2ed35"},"source":"print(\"There are \", len(X_train), \"images in the training dataset\")     # checking total number of records / data points available in the X_train dataset\nprint(\"There are \", len(X_test), \"images in the test dataset\")     # checking total number of records / data points available in the X_test dataset","execution_count":4,"outputs":[{"name":"stdout","text":"There are  60000 images in the training dataset\nThere are  10000 images in the test dataset\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"12mEV-er2b7s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6da758cf-961b-419a-aa6b-1e10d4e35b6f","cell_id":"00011-d61d1fef-c66d-40c4-9ec2-8532adbe12d7"},"source":"# Checking the shape of one image\nX_train[0].shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(28, 28)"},"metadata":{}}]},{"cell_type":"markdown","source":"Each image in the dataset is of shape 28X28 numbers (i.e. pixels)","metadata":{"id":"hjJAlpfr296r","colab_type":"text","cell_id":"00012-ec51735c-7324-417d-bd0c-de726f1173fd"}},{"cell_type":"code","metadata":{"id":"yZTMGFdy28lK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6cb19852-58fd-4fab-bef6-f78d7cbfa704","cell_id":"00013-0166d566-eaee-4230-a310-d7da86c84686"},"source":"# Take a look how one image looks like\nX_train[0]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"markdown","source":"Only numbers! Can't understand what digit does it represent. \n\nThere is a function in matplotlib called as 'matshow()', it helps you to display the image of the array of numbers","metadata":{"id":"MMsn02nQ3TvA","colab_type":"text","cell_id":"00014-9a7ddedc-37d0-4e15-a621-5254a636a06f"}},{"cell_type":"code","metadata":{"id":"JDEEhHTt3Qsj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":293},"outputId":"bf4ccd91-f52a-434e-ca93-014d5952afc5","cell_id":"00015-05de3e89-ce26-4b3c-ade7-698a38cb1e24"},"source":"plt.matshow(X_train[20])","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f2409889668>"},"metadata":{}},{"data":{"text/plain":"<Figure size 288x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOwklEQVR4nO3de4xc9XnG8efBrG0wl9ohGMfcApi2oRKGbCAF0rqiTShJBVQqxWqQUasaqTEFKY1KUSQsVVFpuEZUIExwcBSgQuVmqaiJ6xIuJXJYUwffaLnUVjC+4DpgSBvbu377xx7aBXZ/s7tzObP7fj+StbPnnZnzcMw+Pmfm7BlHhADkdUjdAQDUixIAkqMEgOQoASA5SgBIjhIAkqulBGxfZPvfbb9q+/o6MpTY3mJ7ve11tvu6IM9y27tsbxiybJbtVbZfqb7O7LJ8S21vq7bhOtsX15jvBNtP2d5ke6Pta6vlXbENC/k6sg3d6fMEbE+R9B+SfkfSG5JekLQwIjZ1NEiB7S2SeiNid91ZJMn2b0h6T9J3I+LXqmXflLQnIm6qinRmRPxlF+VbKum9iLiljkxD2Z4jaU5EvGj7SElrJV0q6Sp1wTYs5LtcHdiGdewJnCPp1Yh4PSL2S/p7SZfUkGPCiIhnJO350OJLJK2obq/Q4P80tRghX9eIiO0R8WJ1+11JmyXNVZdsw0K+jqijBOZK+umQ799QB/+DRykk/cD2WtuL6w4zgtkRsb26vUPS7DrDjGCJ7Zeqw4XaDleGsn2ypLMkrVEXbsMP5ZM6sA15YXB4F0TE2ZJ+V9JXqt3drhWDx3Tddv733ZJOlTRf0nZJt9YbR7J9hKRHJF0XEXuHzrphGw6TryPbsI4S2CbphCHfH18t6xoRsa36ukvSYxo8hOk2O6tjyfePKXfVnOcDImJnRAxExEFJ96rmbWi7R4M/YA9ExKPV4q7ZhsPl69Q2rKMEXpA0z/YnbU+VdIWklTXkGJbtGdWLM7I9Q9LnJW0oP6oWKyUtqm4vkvREjVk+4v0frsplqnEb2rak+yRtjojbhoy6YhuOlK9T27Dj7w5IUvVWxx2SpkhaHhHf6HiIEdg+RYP/+kvSoZIerDuf7YckLZB0jKSdkm6U9LikhyWdKGmrpMsjopYX50bIt0CDu7EhaYukq4ccf3c63wWSnpW0XtLBavENGjzurn0bFvItVAe2YS0lAKB78MIgkBwlACRHCQDJUQJAcpQAkFytJdDFp+RKIl+zujlfN2eTOpuv7j2Brv6LEPma1c35ujmb1MF8dZcAgJo1dbKQ7YskfUuDZ/59OyJuKt1/qqfFdM34v+8PaJ96NG3c62838jWnm/N1czap9fl+oZ9rf+zzcLNxl8B4Lg5ylGfFub5wXOsDMH5rYrX2xp5hS6CZwwEuDgJMAs2UwES4OAiABg5t9wqqtzoWS9J0Hd7u1QEYo2b2BEZ1cZCIWBYRvRHR280vxABZNVMCXX1xEACjM+7DgYjot71E0vf1/xcH2diyZAA6oqnXBCLiSUlPtigLgBpwxiCQHCUAJEcJAMlRAkBylACQHCUAJEcJAMlRAkBylACQHCUAJEcJAMlRAkBylACQHCUAJEcJAMlRAkBylACQHCUAJEcJAMlRAkBylACQHCUAJNf2jyEDRsufPqM4P+bOj3zA1Qf87Mu/VJz3v75lrJFSYE8ASI4SAJKjBIDkKAEgOUoASI4SAJKjBIDkJtV5AlM+Nqs499FHFeexe09xPrB375gzYfS2/t7RxfkTJ91fnJ/xZ9cU56f91ZvFeRzYX5xPVk2VgO0tkt6VNCCpPyJ6WxEKQOe0Yk/gtyJidwueB0ANeE0ASK7ZEghJP7C91vbiVgQC0FnNHg5cEBHbbB8raZXtlyPimaF3qMphsSRN1+FNrg5AqzW1JxAR26qvuyQ9JumcYe6zLCJ6I6K3R9OaWR2ANhh3CdieYfvI929L+rykDa0KBqAzmjkcmC3pMdvvP8+DEfFPLUk1Ti8vnVecb/79vyvOz/z2tcX5STc+P+ZMGL1j1/aX7/Cn5fHGhXcW55d+b1FxHus2lVcwSY27BCLidUlntjALgBrwFiGQHCUAJEcJAMlRAkBylACQHCUAJDeprifQrJVX3Vycf/k//6I4n3n/j1oZJ52fHzel7ggpsScAJEcJAMlRAkBylACQHCUAJEcJAMlRAkBynCcwxEmHTi3Ov7P0tuL8z3+6pDg/dPXaMWeaTKbMnFmcn3d1X1vX/+rC8ucanLKuravvWuwJAMlRAkBylACQHCUAJEcJAMlRAkBylACQ3KQ6T2DG1vb+PvppPeXNNe3r24tzb5xdnPfv2DnmTBPJ/jM/WZzfPOeeDiXBUOwJAMlRAkBylACQHCUAJEcJAMlRAkBylACQ3KQ6T2DuHT8uzs847privNHn2zfy2OlPFOe9V15bnH/i5sl9nsDUN35WnD/07tzifOGR25pa/2kPvVOcH2zq2SeuhnsCtpfb3mV7w5Bls2yvsv1K9bV8tQgAXWs0hwP3S7roQ8uul7Q6IuZJWl19D2ACalgCEfGMpD0fWnyJpBXV7RWSLm1xLgAdMt4XBmdHxPsnyu+QVD4pHkDXavrdgYgISTHS3PZi2322+w5oX7OrA9Bi4y2BnbbnSFL1dddId4yIZRHRGxG9PZo2ztUBaJfxlsBKSYuq24skld8bA9C1Gp4nYPshSQskHWP7DUk3SrpJ0sO2/0TSVkmXtzPkaEV/f3F++t++Vpyv+OJJxfmio7aOOdNQf3jlvxTnP3rwlOK8f9ubTa2/bvuPL7+T3Ox5ABifhiUQEQtHGF3Y4iwAasBpw0BylACQHCUAJEcJAMlRAkBylACQ3KS6nkAjA2+9VZzftr78ruei85c3tf6vfWx9cf6l0369OD+kzecJHDJ9enG+9WtnN/X853/pJ009Hu3BngCQHCUAJEcJAMlRAkBylACQHCUAJEcJAMmlOk+gkZ4Xjizf4fz2rv/N8w4rzo9/uvz4fRd/pjjffl75r7t/xohXiZMkbbr8W+UANbv77XnF+SFvvV2c87kDAFKiBIDkKAEgOUoASI4SAJKjBIDkKAEgOQ9+ilhnHOVZca4n7pXKdzz+q8V532e+16Ek7dHjKcX5gRjoUJL2OPv2a4rzT9zyfIeSdN6aWK29scfDzdgTAJKjBIDkKAEgOUoASI4SAJKjBIDkKAEgOa4nMAYfv6P8+/4HH5jYv5F+oMEpIwcn+G/c7+t9r+4IXanhnoDt5bZ32d4wZNlS29tsr6v+XNzemADaZTSHA/dLumiY5bdHxPzqz5OtjQWgUxqWQEQ8I2lPB7IAqEEzLwwusf1Sdbgws2WJAHTUeEvgbkmnSpovabukW0e6o+3Ftvts9x3QvnGuDkC7jKsEImJnRAxExEFJ90o6p3DfZRHRGxG9PZo23pwA2mRcJWB7zpBvL5O0YaT7AuhuDc8TsP2QpAWSjrH9hqQbJS2wPV9SSNoi6eo2ZkSHfHfv3OJ8oMG/GX/z3BeL8yl7y9cr2HjFncU52qNhCUTEwmEW39eGLABqwGnDQHKUAJAcJQAkRwkAyVECQHKUAJAc1xOYQH6yvzxf+c7Zxfk/LvtccX7sXc1dd/90vVCcDywo59MVTa0e48SeAJAcJQAkRwkAyVECQHKUAJAcJQAkRwkAyXGewBhM3bC1OJ///B8X5589YUtx/uxrpxXnp9xV/mAA/+u64vxYNXcewER3y6f/oTi/57jyeRT9O3a2Mk7XYE8ASI4SAJKjBIDkKAEgOUoASI4SAJKjBIDkOE9gDAZ2/1dxfuIflOdvNnj+U/VvY0yEsfjC4e8U5/dMz/kJWewJAMlRAkBylACQHCUAJEcJAMlRAkBylACQHOcJoGN6dv93cf70/xxenP/mYeXHN+u1bx5dnJ/8R1OL8zjQ4IMhulTDPQHbJ9h+yvYm2xttX1stn2V7le1Xqq8z2x8XQKuN5nCgX9JXI+JTkj4r6Su2PyXpekmrI2KepNXV9wAmmIYlEBHbI+LF6va7kjZLmivpEkkrqrutkHRpu0ICaJ8xvTBo+2RJZ0laI2l2RGyvRjskzW5pMgAdMeoSsH2EpEckXRcRe4fOIiIkDXsVTNuLbffZ7jugfU2FBdB6oyoB2z0aLIAHIuLRavFO23Oq+RxJu4Z7bEQsi4jeiOjtUc7f0gK62WjeHbCk+yRtjojbhoxWSlpU3V4k6YnWxwPQbh7cky/cwb5A0rOS1ks6WC2+QYOvCzws6URJWyVdHhF7Ss91lGfFub6w2cyYpPZ/obc4//pd3ynOL5j+i1bG+YjLzvjt4nzg7fL1Cuq0JlZrb+zxcLOGJwtFxHOShn2wJH6igQmO04aB5CgBIDlKAEiOEgCSowSA5CgBIDmuJ4CuMfX7fcX5N66+qjj/62X3Fue90wbGGukD3lvwy8X5YY//uKnnrwt7AkBylACQHCUAJEcJAMlRAkBylACQHCUAJMd5Apgwev55bXG+5NYlxfmli39YnK94+nPF+a/88OXivLmzEOrDngCQHCUAJEcJAMlRAkBylACQHCUAJEcJAMk1/NyBVuJzB4B6lD53gD0BIDlKAEiOEgCSowSA5CgBIDlKAEiOEgCSa1gCtk+w/ZTtTbY32r62Wr7U9jbb66o/F7c/LoBWG81FRfolfTUiXrR9pKS1tldVs9sj4pb2xQPQbg1LICK2S9pe3X7X9mZJc9sdDEBnjOk1AdsnSzpL0ppq0RLbL9lebntmi7MB6IBRl4DtIyQ9Ium6iNgr6W5Jp0qar8E9hVtHeNxi2322+w5oXwsiA2ilUZWA7R4NFsADEfGoJEXEzogYiIiDku6VdM5wj42IZRHRGxG9PZrWqtwAWmQ07w5Y0n2SNkfEbUOWzxlyt8skbWh9PADtNpp3B86XdKWk9bbXVctukLTQ9nxJIWmLpKvbkhBAW43m3YHnJA33e8hPtj4OgE7jjEEgOUoASI4SAJKjBIDkKAEgOUoASI4SAJKjBIDkKAEgOUoASI4SAJKjBIDkKAEgOUoASI4SAJJzRHRuZfZbkrYOWXSMpN0dCzB25GtON+fr5mxS6/OdFBEfH27Q0RL4yMrtvojorS1AA+RrTjfn6+ZsUmfzcTgAJEcJAMnVXQLLal5/I+RrTjfn6+ZsUgfz1fqaAID61b0nAKBmlACQHCUAJEcJAMlRAkBy/wuZBhBtNXOUxgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"id":"Ovv623nJHbEm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1638635e-7c5c-4ec7-bc58-7cfbd9ca5dae","cell_id":"00016-1051f13d-a720-4403-a8c4-b06fd8e21db7"},"source":"# we can use y_train to cross check\ny_train[20]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"markdown","source":"Now one can easily say the above number is 5. Well we want to build a model that will tell you what digit does that 28X28 array represent.","metadata":{"id":"3LgYJdJV3-DN","colab_type":"text","cell_id":"00017-c44010a7-ff19-417a-8ef4-f1d8867b9815"}},{"cell_type":"code","metadata":{"id":"ug3Tv0zpi5A0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"7670c596-25d3-49e2-9d02-e2689d8039fd","cell_id":"00018-458c5351-b155-46ab-b7c0-7a34a85fea14"},"source":"# code to view the images\nnum_rows, num_cols = 2, 5\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n                     squeeze=True)\n\nfor r in range(num_rows):\n    for c in range(num_cols):\n      \n        image_index = r * 5 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow( X_train[image_index], cmap='gray')\n        ax[r,c].set_title('No. %d' % y_train[image_index])\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":9,"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  \n","output_type":"stream"},{"data":{"text/plain":"<Figure size 864x360 with 10 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"SR7nFyVY7UPU","colab_type":"text","cell_id":"00019-b0a46495-bbfc-4455-b42a-e0f22960dee8"}},{"cell_type":"markdown","source":"Let's normalize our data (i.e. both X_train and X_test). Normalization is a process that changes the range of pixel intensity values to the range 0 to 1.\n\nBut why to normalize?\n\nThe motivation to normalize is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction and reduce the data redundancy. Also, normalizing the data can help you improve the model performance.","metadata":{"id":"tDX1gHtS44Y0","colab_type":"text","cell_id":"00020-7a1800da-f203-46e9-a1bf-034eca1719f7"}},{"cell_type":"code","metadata":{"id":"TYSYGzgr4fuG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4c635f0b-c28c-483a-f328-8f5b00a33404","cell_id":"00021-6e972e51-f47b-481f-b22d-5f2c8633067f"},"source":"\nX_train = X_train / 255\nX_test = X_test / 255\n\n\"\"\"\nWhy divided by 255?\nThe pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value. \"\"\"","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"'\\nWhy divided by 255?\\nThe pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value. '"},"metadata":{}}]},{"cell_type":"markdown","source":"Now if you look at the data, each pixel value should be in range 0 to 1.","metadata":{"id":"dHPqEcJT6xIx","colab_type":"text","cell_id":"00022-48315322-d4da-4f90-978e-27f8c1a7db16"}},{"cell_type":"code","metadata":{"id":"SGxTk0bM6lA4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6014b3a9-3129-4ed1-98d7-c224d3edb3b4","cell_id":"00023-03d5c2c8-297d-4ca2-ae57-72e409bd5588"},"source":"X_train[0]","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.05490196,\n        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.17647059,\n        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.18039216,\n        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ]])"},"metadata":{}}]},{"cell_type":"markdown","source":"**Flatten the Data**\n\nWe simply convert a 2 dimensional data (i.e. one image data) to 1 dimensional.\n\nWhy to flatten data?\n\nBefore understanding why let's check the shape of the data","metadata":{"id":"vwgjOLnw7Rl1","colab_type":"text","cell_id":"00024-722a015a-98a7-4f60-a5f6-99b202170923"}},{"cell_type":"code","metadata":{"id":"Krewjr8d60yL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5d208958-f82c-4539-f1a1-a44934af4681","cell_id":"00025-1f57fab3-5898-4dce-99b5-c4692296c977"},"source":"X_train.shape","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(60000, 28, 28)"},"metadata":{}}]},{"cell_type":"markdown","source":"The data is 3 dimensional. The first value i.e. 60000 is nothing but the number of records or images in this case. The second and third dimension represent each individual image i.e. each image is of shape 28X28. \n\nMost of the the supervised learning algorithms that execute classification and regression tasks, as well as some deep learning models built for this purposes, are fed with two-dimensional data. Since we have our data as three-dimensional, we will need to flatten our data to make it two-dimensional.","metadata":{"id":"tCghTfZt89QE","colab_type":"text","cell_id":"00026-2c8e37e6-e510-40a3-95cb-4028b3df30db"}},{"cell_type":"code","metadata":{"id":"FTxiNjn287uw","colab_type":"code","colab":{},"cell_id":"00027-a9482231-87d9-4e23-af58-a5bc9ef37592"},"source":"X_train_flattened = X_train.reshape(len(X_train), 28*28)    # converting our 2D array representing an image to one dimensional\nX_test_flattened = X_test.reshape(len(X_test), 28*28)","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Now if you check the shape of our data, it should be 2 dimensional","metadata":{"id":"iHF9he2FCMNG","colab_type":"text","cell_id":"00028-0d5c464b-4e52-412d-8b0a-ebaaaffd6f96"}},{"cell_type":"code","metadata":{"id":"MGA8LsPECJ9O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"37048bae-a598-4932-fe89-939225bf3738","cell_id":"00029-740b0a8f-c3c0-450f-a82c-018ebd557258"},"source":"X_train_flattened.shape","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"(60000, 784)"},"metadata":{}}]},{"cell_type":"markdown","source":"**A sample example showing the conversion of 3D data to 2D**\n![3Dto2D](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/3D+to++2D.png)","metadata":{"id":"2k1BV6lDmYC-","colab_type":"text","cell_id":"00030-2d3f1090-4312-4c3e-84da-dead191d1f16"}},{"cell_type":"markdown","source":"## Building Models\n### Very simple neural network with no hidden layers","metadata":{"id":"2rQqtuN5CY76","colab_type":"text","cell_id":"00031-5b77f068-a8d2-4729-a9fe-4500eaf79140"}},{"cell_type":"markdown","source":"![simple neural network](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/mnist1.png)","metadata":{"id":"GO6UMj04EI19","colab_type":"text","cell_id":"00032-b6eaf661-0822-49e5-a682-39a8bbf5aff1"}},{"cell_type":"markdown","source":"**Define the model**","metadata":{"id":"pMJrUsyqFehV","colab_type":"text","cell_id":"00033-a2fe8bb3-17bd-45fc-a37d-21c5513c8a0f"}},{"cell_type":"code","metadata":{"id":"DTFzdn5MCTeQ","colab_type":"code","colab":{},"cell_id":"00034-f6f8861e-bc99-4ee1-b825-526712d0cacc"},"source":"# Defining the Model using Sigmoid activation function\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')     # The input shape is 784. \n])","execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Defining the Model using softmax activation function\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, input_shape=(784,), activation='softmax')     # The input shape is 784. \n])","metadata":{"tags":[],"cell_id":"00036-dec5983d-720d-4dd1-8fda-bca197744652"},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"The activation function used here is 'sigmoid'. Do you recall why was it so from the [Binary Classification Notebook](https://github.com/dphi-official/Deep_Learning_Bootcamp/blob/master/DL%20For%20Classification/DL_Day6_Binary_Classification.ipynb)?","metadata":{"id":"Em_HXNMaF0AU","colab_type":"text","cell_id":"00035-8c2f3ba3-29db-46ce-a5bf-60c9afe29a9f"}},{"cell_type":"code","metadata":{"id":"rEJSaVUlNlUM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":191},"outputId":"f75f53b7-5ff0-4fd9-9495-3380531e3526","cell_id":"00036-8f7b1322-7735-4794-a569-a6d82fa7a9bd"},"source":"model.summary()","execution_count":23,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 10)                7850      \n=================================================================\nTotal params: 7,850\nTrainable params: 7,850\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Generally for multi-class classification problem, it is suggested to use softmax. We tried both softmax activation and sigmoid activation, but sigmoid found to give better performance. You can also try using both and keep the one which gives better performance.","metadata":{"id":"QGGoOmoVxr57","colab_type":"text","cell_id":"00037-bae5a813-df24-4fc0-b8d4-553025d30bad"}},{"cell_type":"markdown","source":"**Compile the model**","metadata":{"id":"ns3xpXRxFhV6","colab_type":"text","cell_id":"00038-cf7c8530-4bee-4fbf-ace0-37427b7e88ca"}},{"cell_type":"code","metadata":{"id":"w333bVueFdTZ","colab_type":"code","colab":{},"cell_id":"00039-f300ab5c-08b9-4dc2-b3d2-b51f6ac21a9f"},"source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"*  **adam** is an optimization algorithm which is faster than Stochastic Gradient Descent. If you remember from the learning material of Day 4 (i.e. working of neural networks), we know that Stochastic Gradient Descent (SGD in short) is just a type of Gradient Descent algorithm.\n\n*  **sparse_categorical_crossentropy** is a loss function similar to **binary_crossentropy** (discussed in Binary Classification Notebook), the only difference is that if the target variable is binary we use binary_crossentropy but if your target values are normal integers more then two, use sparse categorical crossentropy. Why not use **categorical_crossentropy**? You may ask. Well, [this article](https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/) will help you understand it.\n\n*  The metrics used to evaluate the model is **accuracy**. Accuracy calculates how often the predictions calculated by the model are correct.","metadata":{"id":"mFx4eplPGds9","colab_type":"text","cell_id":"00040-389dacfd-ec50-4cf5-b46d-a0fcf21601a8"}},{"cell_type":"markdown","source":"**Fit the model**","metadata":{"id":"VeSNBYcYJKNp","colab_type":"text","cell_id":"00041-ff1c5ecf-4df5-4ce2-8abe-a6198e509e0b"}},{"cell_type":"code","metadata":{"id":"pEhPuikwGaQg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"d4cecd6f-f59a-49f7-e312-c3480312210a","cell_id":"00042-febb3c2c-2e50-48b5-8ca5-f137bb601f19"},"source":"model.fit(X_train_flattened, y_train, epochs=5)","execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4699 - accuracy: 0.8781\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3038 - accuracy: 0.9156\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2840 - accuracy: 0.9209\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2736 - accuracy: 0.9233\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2669 - accuracy: 0.9260\n","output_type":"stream"},{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f2407127a20>"},"metadata":{}}]},{"cell_type":"markdown","source":"You can play with different number of epochs.","metadata":{"id":"WmIv3thYJYAD","colab_type":"text","cell_id":"00043-98ca8086-38a0-4d1f-90ba-2e7335ed52d1"}},{"cell_type":"markdown","source":"**Evaluate the model on unseen data (i.e. X_test_flattened)**","metadata":{"id":"o2LDdci5JdfE","colab_type":"text","cell_id":"00044-4988d94c-af8d-4e0f-8cc6-a897b50c53d9"}},{"cell_type":"code","metadata":{"id":"onu3n0QzJO1K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"9582bdfe-bd69-4723-c972-e8b2c171f20a","cell_id":"00045-371dc369-a59d-4c16-88b0-ba9c24d103fa"},"source":"#sigmoid activation function\nmodel.evaluate(X_test_flattened, y_test)","execution_count":18,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9285\n","output_type":"stream"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"[0.26594749093055725, 0.9284999966621399]"},"metadata":{}}]},{"cell_type":"code","source":"#softmax activation function\nmodel.evaluate(X_test_flattened, y_test)","metadata":{"tags":[],"cell_id":"00048-6c267a82-1374-4587-b1d9-a8ee25998def"},"outputs":[{"name":"stdout","text":"313/313 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9255\n","output_type":"stream"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[0.27087727189064026, 0.9254999756813049]"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"The performance of the model on very simple model with no hidden layer is 92.6 %. Not Bad!","metadata":{"id":"WT3uMdwaJuO9","colab_type":"text","cell_id":"00046-e2b14094-a48b-4ad0-9403-18755e7d8afb"}},{"cell_type":"markdown","source":"**predict for the X_test**","metadata":{"id":"9Dmd6wUDJ8wU","colab_type":"text","cell_id":"00047-0f4a948f-e63c-4a5b-88be-21c4b342721f"}},{"cell_type":"code","metadata":{"id":"cSPYvO3qJsmq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"0702c476-42ee-4ff7-e787-7db10d2e4b12","cell_id":"00048-16170fdc-5767-41ff-82a1-09a914ba788d"},"source":"y_predicted = model.predict(X_test_flattened)\ny_predicted[0]","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([3.9690449e-06, 4.2548083e-11, 7.8795274e-06, 3.7454606e-03,\n       4.1587839e-07, 2.2729089e-05, 1.6092555e-10, 9.9592280e-01,\n       1.7360280e-05, 2.7941039e-04], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"The above numbers are the probabilities values for different digits. The maximum probability will confirm what is the predicted digit for first image in X_test.\n\nThe value at the 0th index in above array of numbers is saying the probability of the digit being 0. \n\n**Generalize:** The value at the nth index in above array of numbers is saying the probability of the digit being n","metadata":{"id":"jQ6HhcLrKFfb","colab_type":"text","cell_id":"00049-646a8d6b-4e7f-42a0-a056-523e391522ed"}},{"cell_type":"markdown","source":"**np.argmax finds a maximum element from an array and returns the index of it**","metadata":{"id":"LWeHXcDmKudF","colab_type":"text","cell_id":"00050-1902ae7c-e7f2-46cf-a3b7-38c0dd0a5e5b"}},{"cell_type":"code","metadata":{"id":"QZ95EnDgKEnK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"094d751b-e943-4639-d0e9-0bde2da287bf","cell_id":"00051-174f2141-8df7-46c6-9168-c58cf0c11784"},"source":"np.argmax(y_predicted[0])","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"markdown","source":"The predicted digit is 7.","metadata":{"id":"ZYsBH4_VKy7z","colab_type":"text","cell_id":"00052-b8ea5ce1-d44d-483b-a477-5fabfc40dbef"}},{"cell_type":"markdown","source":"Let's see the original digit at first index in X_test. Can see this using matshow() function.","metadata":{"id":"t3LlzcSXLbw6","colab_type":"text","cell_id":"00053-c7ba9543-a051-45c8-a80c-1acc748caa00"}},{"cell_type":"code","metadata":{"id":"pbaI7nX6KyIc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":293},"outputId":"5a91519b-7893-45a6-d049-0b758595d342","cell_id":"00054-75c21c87-3b96-415f-8eaf-aa624e762f2b"},"source":"plt.matshow(X_test[0])","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f2407171b00>"},"metadata":{}},{"data":{"text/plain":"<Figure size 288x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"markdown","source":"Hence the prediction is correct","metadata":{"id":"Qym97msLLr9A","colab_type":"text","cell_id":"00055-8fdb361b-636d-44f4-9880-27f47a991eab"}},{"cell_type":"markdown","source":"### Building Neural Network Model Using hidden layer","metadata":{"id":"tIGCWjGtLzPj","colab_type":"text","cell_id":"00056-d38ac131-9a34-42e3-a112-ef1e5c59e7c6"}},{"cell_type":"code","metadata":{"id":"v-tS8rVaLqwl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"b829a770-3b4c-4c15-f5c4-4dd9e7adb0a5","cell_id":"00057-ecb4e54e-82b9-44ce-bd1c-8a45b102502a"},"source":"# Defining the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n    tf.keras.layers.Dense(100, input_shape=(100,),activation='relu'),\n    tf.keras.layers.Dense(10, activation='sigmoid')\n])\nmodel.summary()\n","execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (None, 100)               78500     \n_________________________________________________________________\ndense_3 (Dense)              (None, 100)               10100     \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                1010      \n=================================================================\nTotal params: 89,610\nTrainable params: 89,610\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"Ff-aZb_RN0qD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"cf0a7d22-5dfa-4c17-b647-19a402bb9b79","cell_id":"00058-3ffdd381-4960-4f35-afbc-a2dbda8b0084"},"source":"# Compiling the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)","execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.3745 - accuracy: 0.8954\nEpoch 2/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.1532 - accuracy: 0.9549\nEpoch 3/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.1114 - accuracy: 0.9671\nEpoch 4/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0861 - accuracy: 0.9738\nEpoch 5/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - accuracy: 0.9792\n","output_type":"stream"},{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f2407004518>"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"thtxdz9mM4hG","colab_type":"code","colab":{},"cell_id":"00059-f7ad2c92-00d9-4c5f-a4fe-03e621f39f12"},"source":"# Evaluate the model\nmodel.evaluate(X_test_flattened,y_test)","execution_count":31,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9731\n","output_type":"stream"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"[0.0871199518442154, 0.9731000065803528]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Try softmax activation function","metadata":{"tags":[],"cell_id":"00063-ba7b0aa8-61be-4d4d-bfb4-2e11cd42a08e"}},{"cell_type":"code","source":"# Defining the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n    tf.keras.layers.Dense(100, input_shape=(100,),activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.summary()\n","metadata":{"tags":[],"cell_id":"00063-282dd110-013a-4881-8454-57161baab1ea"},"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_11 (Dense)             (None, 100)               78500     \n_________________________________________________________________\ndense_12 (Dense)             (None, 100)               10100     \n_________________________________________________________________\ndense_13 (Dense)             (None, 10)                1010      \n=================================================================\nTotal params: 89,610\nTrainable params: 89,610\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)","metadata":{"tags":[],"cell_id":"00065-28bc8552-6ec0-4a06-b8ba-1b9e1122ffdd"},"outputs":[{"name":"stdout","text":"Epoch 1/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0530 - accuracy: 0.9833\nEpoch 2/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0418 - accuracy: 0.9863\nEpoch 3/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0336 - accuracy: 0.9894\nEpoch 4/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9909\nEpoch 5/5\n469/469 [==============================] - 2s 4ms/step - loss: 0.0231 - accuracy: 0.9929\n","output_type":"stream"},{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f238af535c0>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# Evaluate the model\nmodel.evaluate(X_test_flattened,y_test)","metadata":{"tags":[],"cell_id":"00065-e1fe5170-6161-49f9-932f-5c8110ff6cb0"},"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9768\n","output_type":"stream"},{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"[0.076064333319664, 0.9768000245094299]"},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"**Try yourself**: \nChange the values of epochs and try adding more hidden layers. Are you able to increase the accuracy above 97.5%?","metadata":{"id":"57Mi2yePNGmb","colab_type":"text","cell_id":"00060-c099cadd-2674-4eb9-a4dc-741d7a33ea5d"}},{"cell_type":"markdown","source":"# Saving and loading the model","metadata":{"id":"6QQyh13YlL-X","colab_type":"text","cell_id":"00061-092c836d-ce9f-4f7e-b492-db555983714f"}},{"cell_type":"code","metadata":{"id":"7ihfjL2GlGAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d42c0237-23df-40c2-d26f-cfff7e30bd13","cell_id":"00062-7cbe5c40-8728-4063-81e5-3d8e882f9526"},"source":"# saving the model\nsave_dir = \"/results/\"\nmodel_name = 'keras_mnist.h5'\nmodel.save(model_name)\nmodel_path = save_dir + model_name\nprint('Saved trained model at %s ' % model_path)","execution_count":null,"outputs":[{"name":"stdout","text":"Saved trained model at /results/keras_mnist.h5 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Summary\n*  We learned why we need to normalize and flatten the data.\n*  We observed the performance of very simple neural network with no hidden layer and that of with one hidden layer with 100 hidden neurons. The performance of later model was better than earlier","metadata":{"id":"F91VHEpJONIF","colab_type":"text","cell_id":"00063-369c0cbe-5559-47c1-9f1a-e61abdc2866e"}},{"cell_type":"markdown","source":"### **Reference**\n[Neural Network For Handwritten Digits Classification](https://www.youtube.com/watch?v=iqQgED9vV7k&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=7)","metadata":{"id":"JecJgLmCO5pq","colab_type":"text","cell_id":"00064-5c38ebb5-864d-4444-b7a8-c08b5421e48a"}},{"cell_type":"markdown","source":"# **Exercises**\n*  Try different optimizers and losses in the above models and check the performance of the models.\n  *  [Different losses that can be used](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n  *  [Different optimizers that can be used](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)","metadata":{"id":"v7vYNxsJPSsc","colab_type":"text","cell_id":"00065-c7ccf0b6-e4f1-4650-97f0-b8ab19088c51"}},{"cell_type":"markdown","source":"## Trying different Losses","metadata":{"tags":[],"cell_id":"00073-c4e3deaf-a1a7-42fc-b804-e2783f6e1f63"}},{"cell_type":"markdown","source":"### Adagrad optimizer performs better than adam","metadata":{"tags":[],"cell_id":"00074-6bda3e22-9494-4b38-860e-7f701f8d3449"}},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adagrad',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)","metadata":{"tags":[],"cell_id":"00074-be2be0bd-f714-435a-ae6e-2d59f5ec570c"},"outputs":[{"name":"stdout","text":"Epoch 1/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0102 - accuracy: 0.9980\nEpoch 2/5\n469/469 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9981\nEpoch 3/5\n469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9982\nEpoch 4/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0095 - accuracy: 0.9983\nEpoch 5/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0094 - accuracy: 0.9983\n","output_type":"stream"},{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f23a865eb00>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"model.evaluate(X_test_flattened,y_test)\n","metadata":{"tags":[],"cell_id":"00075-1066614d-c9dd-466f-a6d2-d2560bfbea6a"},"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9804\n","output_type":"stream"},{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"[0.0684690847992897, 0.980400025844574]"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"### SDG optimizer","metadata":{"tags":[],"cell_id":"00077-b37f4211-3211-4436-b9d9-d24b8ffd7d64"}},{"cell_type":"code","source":"opt = tf.keras.optimizers.SGD(learning_rate=0.01)","metadata":{"tags":[],"cell_id":"00078-b700c16e-3904-4a5f-8066-67afb5d29897"},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer=opt,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)","metadata":{"tags":[],"cell_id":"00076-f5e35651-a85f-47e7-859d-57652f3c1de5"},"outputs":[{"name":"stdout","text":"Epoch 1/5\n469/469 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9983\nEpoch 2/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9984\nEpoch 3/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9986\nEpoch 4/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9987\nEpoch 5/5\n469/469 [==============================] - 2s 5ms/step - loss: 0.0082 - accuracy: 0.9987\n","output_type":"stream"},{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f23a844c5f8>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"model.evaluate(X_test_flattened,y_test)\n","metadata":{"tags":[],"cell_id":"00079-edfc161a-bc8e-45df-987e-90eae7e7fe96"},"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9795\n","output_type":"stream"},{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"[0.0683799684047699, 0.9794999957084656]"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"00081-bf18ac9b-933b-447d-bb09-3b61ea557b1f"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"MNIST Multi-class classification model.ipynb","provenance":[],"collapsed_sections":["JecJgLmCO5pq"],"include_colab_link":true},"deepnote_notebook_id":"213a6279-5030-403a-9eee-bfef32eae9bb","deepnote_execution_queue":[]}}