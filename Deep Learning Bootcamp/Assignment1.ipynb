{"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Justus-coded/DPhi-Deep-Learning-Bootcamp/blob/master/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text","cell_id":"00000-20b90954-e3f9-4fb1-9c2d-7d8410ec4aad"}},{"cell_type":"code","metadata":{"id":"vKlTCmOnNj7m","colab_type":"code","colab":{},"cell_id":"00001-a210e5c9-f4d1-4169-9a74-2d64bf050a6b"},"source":"import pandas as pd\n \nbank_note_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/training_set_label.csv\" )","outputs":[{"output_type":"error","ename":"KernelInterrupted","evalue":"Execution interrupted by the Jupyter kernel.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."]}],"execution_count":null},{"cell_type":"code","metadata":{"id":"-b6Bbm_TN-7o","colab_type":"code","colab":{},"cell_id":"00002-de07baf5-0cd1-4d81-a796-df0f5fecf4d2"},"source":"test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/testing_set_label.csv')","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"id":"6DjEUf4yOACF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"cb528980-6bf6-49e3-c869-7b491159501d","cell_id":"00003-34471421-fff9-4c08-975a-efff311bda2b","output_cleared":false},"source":"bank_note_data.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":5,"column_count":5,"columns":[{"name":"VWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-3.9411,"max":3.2718,"histogram":[{"bin_start":-3.9411,"bin_end":-3.21981,"count":1},{"bin_start":-3.21981,"bin_end":-2.49852,"count":0},{"bin_start":-2.49852,"bin_end":-1.7772299999999999,"count":0},{"bin_start":-1.7772299999999999,"bin_end":-1.05594,"count":0},{"bin_start":-1.05594,"bin_end":-0.33465000000000034,"count":0},{"bin_start":-0.33465000000000034,"bin_end":0.3866400000000003,"count":0},{"bin_start":0.3866400000000003,"bin_end":1.10793,"count":1},{"bin_start":1.10793,"bin_end":1.8292199999999998,"count":0},{"bin_start":1.8292199999999998,"bin_end":2.5505099999999996,"count":1},{"bin_start":2.5505099999999996,"bin_end":3.2718,"count":2}]}},{"name":"SWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-12.8792,"max":1.7837,"histogram":[{"bin_start":-12.8792,"bin_end":-11.41291,"count":1},{"bin_start":-11.41291,"bin_end":-9.946620000000001,"count":0},{"bin_start":-9.946620000000001,"bin_end":-8.48033,"count":0},{"bin_start":-8.48033,"bin_end":-7.0140400000000005,"count":0},{"bin_start":-7.0140400000000005,"bin_end":-5.547750000000001,"count":0},{"bin_start":-5.547750000000001,"bin_end":-4.08146,"count":2},{"bin_start":-4.08146,"bin_end":-2.615170000000001,"count":1},{"bin_start":-2.615170000000001,"bin_end":-1.1488800000000001,"count":0},{"bin_start":-1.1488800000000001,"bin_end":0.31741000000000064,"count":0},{"bin_start":0.31741000000000064,"bin_end":1.7837,"count":1}]}},{"name":"CWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":2.1161,"max":13.0597,"histogram":[{"bin_start":2.1161,"bin_end":3.21046,"count":2},{"bin_start":3.21046,"bin_end":4.304819999999999,"count":1},{"bin_start":4.304819999999999,"bin_end":5.399179999999999,"count":0},{"bin_start":5.399179999999999,"bin_end":6.493539999999999,"count":1},{"bin_start":6.493539999999999,"bin_end":7.587899999999999,"count":0},{"bin_start":7.587899999999999,"bin_end":8.68226,"count":0},{"bin_start":8.68226,"bin_end":9.77662,"count":0},{"bin_start":9.77662,"bin_end":10.87098,"count":0},{"bin_start":10.87098,"bin_end":11.96534,"count":0},{"bin_start":11.96534,"bin_end":13.0597,"count":1}]}},{"name":"EI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-3.3125,"max":0.61334,"histogram":[{"bin_start":-3.3125,"bin_end":-2.919916,"count":1},{"bin_start":-2.919916,"bin_end":-2.527332,"count":0},{"bin_start":-2.527332,"bin_end":-2.134748,"count":0},{"bin_start":-2.134748,"bin_end":-1.742164,"count":0},{"bin_start":-1.742164,"bin_end":-1.34958,"count":0},{"bin_start":-1.34958,"bin_end":-0.9569960000000002,"count":1},{"bin_start":-0.9569960000000002,"bin_end":-0.5644119999999999,"count":1},{"bin_start":-0.5644119999999999,"bin_end":-0.1718280000000001,"count":0},{"bin_start":-0.1718280000000001,"bin_end":0.22075599999999973,"count":1},{"bin_start":0.22075599999999973,"bin_end":0.61334,"count":1}]}},{"name":"Class","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":0,"max":1,"histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"VWTI":2.2634,"SWTI":-4.4862,"CWTI":3.6558,"EI":-0.61251,"Class":0,"_deepnote_index_column":0},{"VWTI":3.2718,"SWTI":1.7837,"CWTI":2.1161,"EI":0.61334,"Class":0,"_deepnote_index_column":1},{"VWTI":-3.9411,"SWTI":-12.8792,"CWTI":13.0597,"EI":-3.3125,"Class":1,"_deepnote_index_column":2},{"VWTI":0.5195,"SWTI":-3.2633,"CWTI":3.0895,"EI":-0.9849,"Class":0,"_deepnote_index_column":3},{"VWTI":2.5698,"SWTI":-4.4076,"CWTI":5.9856,"EI":0.078002,"Class":0,"_deepnote_index_column":4}],"rows_bottom":null},"text/plain":"     VWTI     SWTI     CWTI        EI  Class\n0  2.2634  -4.4862   3.6558 -0.612510      0\n1  3.2718   1.7837   2.1161  0.613340      0\n2 -3.9411 -12.8792  13.0597 -3.312500      1\n3  0.5195  -3.2633   3.0895 -0.984900      0\n4  2.5698  -4.4076   5.9856  0.078002      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VWTI</th>\n      <th>SWTI</th>\n      <th>CWTI</th>\n      <th>EI</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.2634</td>\n      <td>-4.4862</td>\n      <td>3.6558</td>\n      <td>-0.612510</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.2718</td>\n      <td>1.7837</td>\n      <td>2.1161</td>\n      <td>0.613340</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-3.9411</td>\n      <td>-12.8792</td>\n      <td>13.0597</td>\n      <td>-3.312500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5195</td>\n      <td>-3.2633</td>\n      <td>3.0895</td>\n      <td>-0.984900</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.5698</td>\n      <td>-4.4076</td>\n      <td>5.9856</td>\n      <td>0.078002</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"4f_m1ELjOiJP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"outputId":"15017d0c-83a8-4720-9875-0b8e7ffe7d10","cell_id":"00004-b321621c-6529-40a6-9299-9a067a82a01d"},"source":"bank_note_data.info()","execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1096 entries, 0 to 1095\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   VWTI    1096 non-null   float64\n 1   SWTI    1096 non-null   float64\n 2   CWTI    1096 non-null   float64\n 3   EI      1096 non-null   float64\n 4   Class   1096 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 42.9 KB\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"FxyaKboXOCPs","colab_type":"code","colab":{},"cell_id":"00005-787571c2-7472-4557-b387-791c9a6ef006"},"source":"from sklearn.model_selection import train_test_split","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypNDBPCCOVbV","colab_type":"code","colab":{},"cell_id":"00006-eed9d876-6513-455e-b24b-5190e10f8faa"},"source":"X = bank_note_data.drop(columns=['Class'])\ny = bank_note_data['Class']","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lc0SFEcmf7Zf","colab_type":"code","colab":{},"cell_id":"00007-8603645d-dee5-4ff5-b357-eb5db6fe0425"},"source":"from sklearn.preprocessing import MinMaxScaler\nminmax = MinMaxScaler ()\nX_scaled = minmax.fit_transform(X)","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDouW5qAOMwb","colab_type":"code","colab":{},"cell_id":"00008-5c794d2c-b667-47ff-ad73-0bc9cca894d8"},"source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)","execution_count":10,"outputs":[]},{"cell_type":"code","source":"pip install tensorflow","metadata":{"tags":[],"cell_id":"00009-374ef57f-ed28-4b8b-9cd8-992814feb62e"},"outputs":[{"name":"stdout","text":"Collecting tensorflow\n  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n\u001b[K     |████████████████████████████████| 320.4 MB 7.3 kB/s eta 0:00:011  |                                | 225 kB 2.1 MB/s eta 0:02:32     |                                | 583 kB 2.1 MB/s eta 0:02:32     |▉                               | 8.0 MB 7.5 MB/s eta 0:00:42     |▉                               | 8.7 MB 7.5 MB/s eta 0:00:42     |█                               | 8.9 MB 7.5 MB/s eta 0:00:42     |█                               | 9.1 MB 7.5 MB/s eta 0:00:42     |█                               | 9.2 MB 7.5 MB/s eta 0:00:42     |█▎                              | 12.4 MB 7.5 MB/s eta 0:00:41     |█▎                              | 12.9 MB 7.5 MB/s eta 0:00:41     |█▉                              | 18.6 MB 3.3 MB/s eta 0:01:33     |██▏                             | 21.8 MB 3.3 MB/s eta 0:01:3229.3 MB 6.2 MB/s eta 0:00:48     |███▍                            | 34.1 MB 6.2 MB/s eta 0:00:47     |█████▍                          | 53.6 MB 2.5 MB/s eta 0:01:48     |█████▍                          | 54.1 MB 2.5 MB/s eta 0:01:48     |█████▍                          | 54.5 MB 2.5 MB/s eta 0:01:48     |█████▌                          | 54.9 MB 2.5 MB/s eta 0:01:48     |█████▋                          | 56.0 MB 3.0 MB/s eta 0:01:29     |██████                          | 60.9 MB 3.0 MB/s eta 0:01:27██▌                         | 64.9 MB 9.1 MB/s eta 0:00:29     |██████▋                         | 66.2 MB 9.1 MB/s eta 0:00:29██▊                         | 67.3 MB 9.1 MB/s eta 0:00:28     |███████▋                        | 75.8 MB 6.9 MB/s eta 0:00:36     |████████                        | 80.3 MB 6.9 MB/s eta 0:00:35��████▍                       | 84.0 MB 1.8 MB/s eta 0:02:14     |████████▊                       | 87.7 MB 1.8 MB/s eta 0:02:12     |█████████                       | 89.5 MB 13.0 MB/s eta 0:00:18     |█████████                       | 89.7 MB 13.0 MB/s eta 0:00:18     |█████████                       | 89.9 MB 13.0 MB/s eta 0:00:1818               | 92.0 MB 13.0 MB/s eta 0:00:18     |██████████                      | 99.4 MB 3.5 MB/s eta 0:01:04     |██████████                      | 100.2 MB 3.5 MB/s eta 0:01:04     |██████████▎                     | 102.4 MB 3.5 MB/s eta 0:01:03     |██████████▎                     | 103.2 MB 3.5 MB/s eta 0:01:03     |██████████▍                     | 104.3 MB 2.6 MB/s eta 0:01:23    |██████████▊                     | 107.4 MB 2.6 MB/s eta 0:01:22     |██████████▉                     | 108.9 MB 2.0 MB/s eta 0:01:44     |███████████▎                    | 112.4 MB 2.0 MB/s eta 0:01:42��████████▍                   | 123.5 MB 3.5 MB/s eta 0:00:57     |█████████████▊                  | 137.0 MB 7.9 MB/s eta 0:00:24     |██████████████▏                 | 141.6 MB 7.9 MB/s eta 0:00:23     |██████████████▏                 | 142.0 MB 7.9 MB/s eta 0:00:23     |██████████████▏                 | 142.3 MB 7.9 MB/s eta 0:00:23     |██████████████▎                 | 142.8 MB 3.4 MB/s eta 0:00:52     |██████████████▎                 | 143.0 MB 3.4 MB/s eta 0:00:52███▍                 | 143.7 MB 3.4 MB/s eta 0:00:52███▊                 | 146.9 MB 3.4 MB/s eta 0:00:51     |███████████████                 | 150.9 MB 4.3 MB/s eta 0:00:40     |███████████████▎                | 153.2 MB 4.3 MB/s eta 0:00:40     |███████████████▍                | 154.2 MB 4.3 MB/s eta 0:00:39     |███████████████▋                | 156.3 MB 4.3 MB/s eta 0:00:39     |████████████████                | 159.9 MB 3.7 MB/s eta 0:00:44�               | 169.2 MB 10.6 MB/s eta 0:00:15     |██████████████████              | 181.2 MB 6.9 MB/s eta 0:00:21     |██████████████████▋             | 186.1 MB 3.4 MB/s eta 0:00:40     |██████████████████▋             | 186.3 MB 3.4 MB/s eta 0:00:40     |███████████████████▍            | 194.6 MB 7.2 MB/s eta 0:00:18   | 195.3 MB 2.3 MB/s eta 0:00:54     |████████████████████            | 201.3 MB 2.3 MB/s eta 0:00:51�████████▎           | 203.3 MB 2.3 MB/s eta 0:00:50     |████████████████████▉           | 208.0 MB 15.6 MB/s eta 0:00:08     |█████████████████████           | 210.4 MB 15.6 MB/s eta 0:00:08     |█████████████████████▎          | 212.5 MB 15.6 MB/s eta 0:00:07�█████████████▉          | 218.8 MB 9.1 MB/s eta 0:00:12     |██████████████████████▎         | 223.5 MB 13.0 MB/s eta 0:00:08     |██████████████████████▌         | 225.2 MB 13.0 MB/s eta 0:00:08        | 230.3 MB 13.0 MB/s eta 0:00:07     |███████████████████████▏        | 231.4 MB 13.0 MB/s eta 0:00:07█████▌        | 235.4 MB 8.0 MB/s eta 0:00:11     |███████████████████████▋        | 236.0 MB 8.0 MB/s eta 0:00:11██████        | 239.6 MB 8.0 MB/s eta 0:00:11��████████████████▌       | 245.2 MB 7.4 MB/s eta 0:00:11��█████████████████       | 250.4 MB 7.4 MB/s eta 0:00:10��█████████████████       | 251.3 MB 7.4 MB/s eta 0:00:10     |█████████████████████████▏      | 251.9 MB 7.4 MB/s eta 0:00:10     |█████████████████████████▏      | 252.1 MB 7.4 MB/s eta 0:00:10     |█████████████████████████▌      | 254.8 MB 2.1 MB/s eta 0:00:32     |█████████████████████████▌      | 255.5 MB 2.1 MB/s eta 0:00:31     |█████████████████████████▉      | 258.3 MB 2.1 MB/s eta 0:00:30 | 263.4 MB 5.5 MB/s eta 0:00:11 | 270.1 MB 5.8 MB/s eta 0:00:09     |███████████████████████████     | 270.8 MB 5.8 MB/s eta 0:00:09     |███████████████████████████     | 271.0 MB 5.8 MB/s eta 0:00:09     |███████████████████████████     | 271.2 MB 5.8 MB/s eta 0:00:09     |███████████████████████████▏    | 271.9 MB 5.8 MB/s eta 0:00:09��█████████    | 279.3 MB 1.8 MB/s eta 0:00:23     |████████████████████████████▎   | 283.7 MB 1.8 MB/s eta 0:00:20     |████████████████████████████▍   | 284.6 MB 1.8 MB/s eta 0:00:20:00:02     |█████████████████████████████▍  | 294.4 MB 14.9 MB/s eta 0:00:02     |█████████████████████████████▋  | 296.5 MB 27.9 MB/s eta 0:00:01     |█████████████████████████████▋  | 297.0 MB 27.9 MB/s eta 0:00:01     |█████████████████████████████▊  | 297.7 MB 27.9 MB/s eta 0:00:01ta 0:00:01     |██████████████████████████████  | 300.1 MB 27.9 MB/s eta 0:00:01     |██████████████████████████████▎ | 303.3 MB 28.1 MB/s eta 0:00:01     |███████████████████████████████ | 310.7 MB 28.1 MB/s eta 0:00:01     |███████████████████████████████ | 311.3 MB 28.1 MB/s eta 0:00:01     |███████████████████████████████▊| 317.4 MB 7.4 MB/s eta 0:00:01     |███████████████████████████████▉| 318.2 MB 7.4 MB/s eta 0:00:01     |████████████████████████████████| 319.8 MB 7.4 MB/s eta 0:00:01     |████████████████████████████████| 320.0 MB 7.4 MB/s eta 0:00:01\n\u001b[?25hCollecting scipy==1.4.1\n  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n\u001b[K     |████████████████████████████████| 26.1 MB 49 kB/s  eta 0:00:011    |████▍                           | 3.6 MB 24.3 MB/s eta 0:00:01     |█████████                       | 7.4 MB 24.3 MB/s eta 0:00:01     |███████████▊                    | 9.6 MB 24.3 MB/s eta 0:00:01     |████████████████▋               | 13.6 MB 10.1 MB/s eta 0:00:02     |█████████████████▊              | 14.4 MB 10.1 MB/s eta 0:00:02     |██████████████████              | 14.7 MB 10.1 MB/s eta 0:00:02     |██████████████████▍             | 15.0 MB 10.1 MB/s eta 0:00:02     |█████████████████████▍          | 17.4 MB 10.1 MB/s eta 0:00:01     |█████████████████████▋          | 17.6 MB 10.1 MB/s eta 0:00:01     |██████████████████████          | 17.8 MB 6.8 MB/s eta 0:00:02     |██████████████████████▎         | 18.2 MB 6.8 MB/s eta 0:00:02     |███████████████████████▌        | 19.1 MB 6.8 MB/s eta 0:00:02��█████████████████████████▋  | 24.1 MB 6.8 MB/s eta 0:00:01\n\u001b[?25hCollecting grpcio>=1.8.6\n  Downloading grpcio-1.31.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n\u001b[K     |████████████████████████████████| 3.4 MB 10.8 MB/s eta 0:00:01    |█                               | 102 kB 10.8 MB/s eta 0:00:01     |█████▋                          | 593 kB 10.8 MB/s eta 0:00:01     |███████▍                        | 788 kB 10.8 MB/s eta 0:00:01     |█████████▊                      | 1.0 MB 10.8 MB/s eta 0:00:01     |██████████▊                     | 1.1 MB 10.8 MB/s eta 0:00:01     |██████████████▌                 | 1.5 MB 10.8 MB/s eta 0:00:01     |██████████████████▊             | 2.0 MB 10.8 MB/s eta 0:00:01     |████████████████████████▎       | 2.6 MB 10.8 MB/s eta 0:00:01\n\u001b[?25hCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 1.3 MB/s eta 0:00:011\n\u001b[?25hCollecting tensorboard<3,>=2.3.0\n  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n\u001b[K     |████████████████████████████████| 6.8 MB 6.9 MB/s eta 0:00:01     |██▎                             | 491 kB 6.9 MB/s eta 0:00:01\n\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 118 kB/s eta 0:00:011�████████▉           | 13.1 MB 19.2 MB/s eta 0:00:01     |██████████████████████▍         | 14.1 MB 19.2 MB/s eta 0:00:01     |████████████████████████▋       | 15.5 MB 8.9 MB/s eta 0:00:01     |██████████████████████████▏     | 16.5 MB 8.9 MB/s eta 0:00:01��████████████▎   | 17.8 MB 8.9 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n\u001b[K     |████████████████████████████████| 459 kB 5.4 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta>=0.1.8\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01\n\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 10.3 MB/s eta 0:00:01     |███████▋                        | 686 kB 10.3 MB/s eta 0:00:01     |███████████▍                    | 1.0 MB 10.3 MB/s eta 0:00:01     |███████████████████████▎        | 2.1 MB 10.3 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor>=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting wrapt>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting keras-preprocessing<1.2,>=1.1.1\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 296 kB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.9.2\n  Downloading protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 26.7 MB/s eta 0:00:01\n\u001b[?25hCollecting absl-py>=0.7.0\n  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 21.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/venv/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nCollecting astunparse==1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: wheel>=0.26 in /opt/venv/lib/python3.7/site-packages (from tensorflow) (0.34.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/venv/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n\u001b[K     |████████████████████████████████| 779 kB 5.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/venv/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (47.3.1)\nCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.21.1-py2.py3-none-any.whl (93 kB)\n\u001b[K     |████████████████████████████████| 93 kB 565 kB/s  eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\nCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 7.6 MB/s eta 0:00:01\n\u001b[?25hCollecting markdown>=2.6.8\n  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n\u001b[K     |████████████████████████████████| 88 kB 4.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\nCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n\u001b[K     |███████████████████████████▋    | 40 kB 20.0 MB/s eta 0:00:01     |████████████████████████████████| 47 kB 2.6 MB/s \n\u001b[?25hCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 7.3 MB/s eta 0:00:01\n\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\nCollecting pyasn1>=0.1.3\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 1.9 MB/s  eta 0:00:01\n\u001b[?25hCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n\u001b[K     |████████████████████████████████| 147 kB 19.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\nBuilding wheels for collected packages: termcolor, wrapt\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=549ba651540290e99a7712e3c1bdef389f136abb671ffab97c7e2de3f9f5ce93\n  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71568 sha256=85fe225a41dc5fd73f276395ae47fb4dc5310ffdb7ac188aa9c18e4f4c77c773\n  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built termcolor wrapt\nInstalling collected packages: numpy, scipy, grpcio, opt-einsum, protobuf, tensorboard-plugin-wit, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, werkzeug, absl-py, markdown, tensorboard, tensorflow-estimator, google-pasta, h5py, termcolor, wrapt, keras-preprocessing, astunparse, gast, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.0\n    Uninstalling numpy-1.19.0:\n      Successfully uninstalled numpy-1.19.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.5.1\n    Uninstalling scipy-1.5.1:\n      Successfully uninstalled scipy-1.5.1\nSuccessfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.21.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","metadata":{"id":"GpHT8IsVOtTI","colab_type":"code","colab":{},"cell_id":"00009-1a1ea796-0ff0-4824-80d5-eb145f191991"},"source":"import tensorflow as tf\nfrom tensorflow import  keras\nfrom tensorflow.keras import  Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Dropout","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED204t9OPhZa","colab_type":"code","colab":{},"cell_id":"00010-e9f7998b-0a0c-4a01-aaf8-c8c5240314de"},"source":"model = Sequential()\nmodel.add(Dense(100, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(Dense(50, activation='relu'))\n#model.add(Dropout(0.2))\n\n#model.add(Dense(100, activation='relu'))\n\n#model.add(Dropout(0.2))\n\n#model.add(Dense(50, activation='relu'))\n\n#model.add(Dropout(0.2))\nmodel.add(Dense(25, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(15, activation='relu'))\nmodel.add(Dense(12,activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(2, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhYS1jfNQVNV","colab_type":"code","colab":{},"cell_id":"00011-09f935c3-7264-4bc0-b882-8dbd0f6d25eb"},"source":"from tensorflow.keras.optimizers import Adagrad\nmodel.compile(loss='binary_crossentropy', optimizer=Adagrad(), metrics=['accuracy'])","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ga_uy-T_Qys-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"outputId":"782efcc7-888e-4fed-d130-49eca658ae4a","cell_id":"00012-779461a9-4585-47d7-8c79-df17a9cccdff"},"source":"model.summary()","execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 100)               500       \n_________________________________________________________________\ndense_1 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_2 (Dense)              (None, 25)                1275      \n_________________________________________________________________\ndense_3 (Dense)              (None, 12)                312       \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 13        \n=================================================================\nTotal params: 7,150\nTrainable params: 7,150\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"ucnUCmXSQ_cD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2c4838dc-017a-4c73-89ba-21a3581581bd","cell_id":"00013-a77a63b0-8e85-4bfb-97f1-e9f936194914"},"source":"model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=700, batch_size=50)","execution_count":17,"outputs":[{"name":"stdout","text":"18/18 [==============================] - 0s 16ms/step - loss: 0.5275 - accuracy: 0.8014 - val_loss: 0.4963 - val_accuracy: 0.8682\nEpoch 202/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.5264 - accuracy: 0.8002 - val_loss: 0.4953 - val_accuracy: 0.8727\nEpoch 203/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.5254 - accuracy: 0.8014 - val_loss: 0.4942 - val_accuracy: 0.8727\nEpoch 204/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.5243 - accuracy: 0.8014 - val_loss: 0.4930 - val_accuracy: 0.8727\nEpoch 205/700\n18/18 [==============================] - 0s 25ms/step - loss: 0.5232 - accuracy: 0.8048 - val_loss: 0.4917 - val_accuracy: 0.8727\nEpoch 206/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.5222 - accuracy: 0.8025 - val_loss: 0.4907 - val_accuracy: 0.8727\nEpoch 207/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.5210 - accuracy: 0.8014 - val_loss: 0.4896 - val_accuracy: 0.8727\nEpoch 208/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.5200 - accuracy: 0.8048 - val_loss: 0.4888 - val_accuracy: 0.8727\nEpoch 209/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8071 - val_loss: 0.4877 - val_accuracy: 0.8727\nEpoch 210/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.5177 - accuracy: 0.8071 - val_loss: 0.4865 - val_accuracy: 0.8727\nEpoch 211/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.5166 - accuracy: 0.8094 - val_loss: 0.4852 - val_accuracy: 0.8727\nEpoch 212/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.8094 - val_loss: 0.4842 - val_accuracy: 0.8727\nEpoch 213/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.8105 - val_loss: 0.4831 - val_accuracy: 0.8727\nEpoch 214/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.5132 - accuracy: 0.8116 - val_loss: 0.4818 - val_accuracy: 0.8727\nEpoch 215/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.5120 - accuracy: 0.8116 - val_loss: 0.4809 - val_accuracy: 0.8773\nEpoch 216/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.5109 - accuracy: 0.8151 - val_loss: 0.4797 - val_accuracy: 0.8773\nEpoch 217/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.5097 - accuracy: 0.8151 - val_loss: 0.4787 - val_accuracy: 0.8773\nEpoch 218/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.8185 - val_loss: 0.4774 - val_accuracy: 0.8773\nEpoch 219/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.5075 - accuracy: 0.8185 - val_loss: 0.4761 - val_accuracy: 0.8773\nEpoch 220/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.5063 - accuracy: 0.8196 - val_loss: 0.4748 - val_accuracy: 0.8773\nEpoch 221/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.5052 - accuracy: 0.8196 - val_loss: 0.4737 - val_accuracy: 0.8773\nEpoch 222/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8208 - val_loss: 0.4726 - val_accuracy: 0.8773\nEpoch 223/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.8219 - val_loss: 0.4717 - val_accuracy: 0.8773\nEpoch 224/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.5019 - accuracy: 0.8253 - val_loss: 0.4704 - val_accuracy: 0.8773\nEpoch 225/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.5007 - accuracy: 0.8276 - val_loss: 0.4690 - val_accuracy: 0.8773\nEpoch 226/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.4996 - accuracy: 0.8265 - val_loss: 0.4681 - val_accuracy: 0.8773\nEpoch 227/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4984 - accuracy: 0.8265 - val_loss: 0.4669 - val_accuracy: 0.8773\nEpoch 228/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.4973 - accuracy: 0.8299 - val_loss: 0.4654 - val_accuracy: 0.8773\nEpoch 229/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.4962 - accuracy: 0.8288 - val_loss: 0.4641 - val_accuracy: 0.8773\nEpoch 230/700\n18/18 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.82 - 0s 17ms/step - loss: 0.4951 - accuracy: 0.8276 - val_loss: 0.4631 - val_accuracy: 0.8773\nEpoch 231/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.4939 - accuracy: 0.8311 - val_loss: 0.4618 - val_accuracy: 0.8818\nEpoch 232/700\n18/18 [==============================] - 1s 28ms/step - loss: 0.4928 - accuracy: 0.8299 - val_loss: 0.4607 - val_accuracy: 0.8818\nEpoch 233/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.4917 - accuracy: 0.8322 - val_loss: 0.4597 - val_accuracy: 0.8818\nEpoch 234/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.4906 - accuracy: 0.8322 - val_loss: 0.4586 - val_accuracy: 0.8818\nEpoch 235/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.4895 - accuracy: 0.8333 - val_loss: 0.4576 - val_accuracy: 0.8818\nEpoch 236/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.4883 - accuracy: 0.8322 - val_loss: 0.4566 - val_accuracy: 0.8818\nEpoch 237/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.4871 - accuracy: 0.8333 - val_loss: 0.4554 - val_accuracy: 0.8818\nEpoch 238/700\n18/18 [==============================] - 0s 25ms/step - loss: 0.4860 - accuracy: 0.8356 - val_loss: 0.4542 - val_accuracy: 0.8818\nEpoch 239/700\n18/18 [==============================] - 1s 29ms/step - loss: 0.4849 - accuracy: 0.8402 - val_loss: 0.4531 - val_accuracy: 0.8818\nEpoch 240/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.4838 - accuracy: 0.8379 - val_loss: 0.4519 - val_accuracy: 0.8818\nEpoch 241/700\n18/18 [==============================] - 1s 38ms/step - loss: 0.4827 - accuracy: 0.8402 - val_loss: 0.4510 - val_accuracy: 0.8864\nEpoch 242/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.4815 - accuracy: 0.8402 - val_loss: 0.4497 - val_accuracy: 0.8864\nEpoch 243/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.8402 - val_loss: 0.4486 - val_accuracy: 0.8864\nEpoch 244/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.4792 - accuracy: 0.8402 - val_loss: 0.4476 - val_accuracy: 0.8864\nEpoch 245/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.4781 - accuracy: 0.8447 - val_loss: 0.4461 - val_accuracy: 0.8864\nEpoch 246/700\n18/18 [==============================] - 0s 27ms/step - loss: 0.4769 - accuracy: 0.8402 - val_loss: 0.4452 - val_accuracy: 0.8909\nEpoch 247/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.4758 - accuracy: 0.8436 - val_loss: 0.4442 - val_accuracy: 0.8909\nEpoch 248/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.8459 - val_loss: 0.4429 - val_accuracy: 0.8909\nEpoch 249/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4735 - accuracy: 0.8436 - val_loss: 0.4420 - val_accuracy: 0.8909\nEpoch 250/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.8470 - val_loss: 0.4407 - val_accuracy: 0.8909\nEpoch 251/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.8470 - val_loss: 0.4391 - val_accuracy: 0.8909\nEpoch 252/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.4693 - accuracy: 0.8482 - val_loss: 0.4375 - val_accuracy: 0.8909\nEpoch 253/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.4678 - accuracy: 0.8482 - val_loss: 0.4358 - val_accuracy: 0.8909\nEpoch 254/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4665 - accuracy: 0.8493 - val_loss: 0.4343 - val_accuracy: 0.8909\nEpoch 255/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.8482 - val_loss: 0.4331 - val_accuracy: 0.9000\nEpoch 256/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4637 - accuracy: 0.8493 - val_loss: 0.4319 - val_accuracy: 0.9000\nEpoch 257/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.8527 - val_loss: 0.4310 - val_accuracy: 0.9045\nEpoch 258/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.8562 - val_loss: 0.4295 - val_accuracy: 0.9045\nEpoch 259/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.4599 - accuracy: 0.8539 - val_loss: 0.4286 - val_accuracy: 0.9091\nEpoch 260/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4587 - accuracy: 0.8562 - val_loss: 0.4274 - val_accuracy: 0.9091\nEpoch 261/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4575 - accuracy: 0.8584 - val_loss: 0.4259 - val_accuracy: 0.9091\nEpoch 262/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4563 - accuracy: 0.8573 - val_loss: 0.4246 - val_accuracy: 0.9091\nEpoch 263/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4552 - accuracy: 0.8562 - val_loss: 0.4235 - val_accuracy: 0.9091\nEpoch 264/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.4540 - accuracy: 0.8596 - val_loss: 0.4226 - val_accuracy: 0.9091\nEpoch 265/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4527 - accuracy: 0.8630 - val_loss: 0.4216 - val_accuracy: 0.9091\nEpoch 266/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.8642 - val_loss: 0.4203 - val_accuracy: 0.9091\nEpoch 267/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.4504 - accuracy: 0.8642 - val_loss: 0.4194 - val_accuracy: 0.9091\nEpoch 268/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4492 - accuracy: 0.8642 - val_loss: 0.4179 - val_accuracy: 0.9091\nEpoch 269/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.4481 - accuracy: 0.8653 - val_loss: 0.4166 - val_accuracy: 0.9091\nEpoch 270/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4468 - accuracy: 0.8653 - val_loss: 0.4154 - val_accuracy: 0.9091\nEpoch 271/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4456 - accuracy: 0.8653 - val_loss: 0.4145 - val_accuracy: 0.9136\nEpoch 272/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4445 - accuracy: 0.8664 - val_loss: 0.4132 - val_accuracy: 0.9136\nEpoch 273/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.4433 - accuracy: 0.8664 - val_loss: 0.4122 - val_accuracy: 0.9182\nEpoch 274/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.4421 - accuracy: 0.8676 - val_loss: 0.4111 - val_accuracy: 0.9182\nEpoch 275/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4410 - accuracy: 0.8676 - val_loss: 0.4095 - val_accuracy: 0.9182\nEpoch 276/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.4398 - accuracy: 0.8676 - val_loss: 0.4082 - val_accuracy: 0.9182\nEpoch 277/700\n18/18 [==============================] - 0s 27ms/step - loss: 0.4386 - accuracy: 0.8676 - val_loss: 0.4073 - val_accuracy: 0.9227\nEpoch 278/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.8676 - val_loss: 0.4063 - val_accuracy: 0.9227\nEpoch 279/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4363 - accuracy: 0.8687 - val_loss: 0.4050 - val_accuracy: 0.9227\nEpoch 280/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.8676 - val_loss: 0.4037 - val_accuracy: 0.9227\nEpoch 281/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4339 - accuracy: 0.8687 - val_loss: 0.4025 - val_accuracy: 0.9227\nEpoch 282/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8699 - val_loss: 0.4013 - val_accuracy: 0.9227\nEpoch 283/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.8676 - val_loss: 0.4001 - val_accuracy: 0.9227\nEpoch 284/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4304 - accuracy: 0.8687 - val_loss: 0.3990 - val_accuracy: 0.9227\nEpoch 285/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.4292 - accuracy: 0.8687 - val_loss: 0.3980 - val_accuracy: 0.9227\nEpoch 286/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4281 - accuracy: 0.8687 - val_loss: 0.3969 - val_accuracy: 0.9227\nEpoch 287/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.4270 - accuracy: 0.8687 - val_loss: 0.3959 - val_accuracy: 0.9227\nEpoch 288/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8699 - val_loss: 0.3945 - val_accuracy: 0.9227\nEpoch 289/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4246 - accuracy: 0.8699 - val_loss: 0.3933 - val_accuracy: 0.9227\nEpoch 290/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8710 - val_loss: 0.3921 - val_accuracy: 0.9227\nEpoch 291/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.4223 - accuracy: 0.8710 - val_loss: 0.3909 - val_accuracy: 0.9227\nEpoch 292/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4212 - accuracy: 0.8710 - val_loss: 0.3896 - val_accuracy: 0.9227\nEpoch 293/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.4200 - accuracy: 0.8710 - val_loss: 0.3886 - val_accuracy: 0.9227\nEpoch 294/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4188 - accuracy: 0.8710 - val_loss: 0.3875 - val_accuracy: 0.9227\nEpoch 295/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.4177 - accuracy: 0.8710 - val_loss: 0.3867 - val_accuracy: 0.9227\nEpoch 296/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.4165 - accuracy: 0.8733 - val_loss: 0.3856 - val_accuracy: 0.9227\nEpoch 297/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4154 - accuracy: 0.8733 - val_loss: 0.3847 - val_accuracy: 0.9273\nEpoch 298/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.4142 - accuracy: 0.8767 - val_loss: 0.3835 - val_accuracy: 0.9273\nEpoch 299/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.8767 - val_loss: 0.3825 - val_accuracy: 0.9273\nEpoch 300/700\n18/18 [==============================] - 0s 26ms/step - loss: 0.4119 - accuracy: 0.8790 - val_loss: 0.3810 - val_accuracy: 0.9273\nEpoch 301/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.4108 - accuracy: 0.8756 - val_loss: 0.3799 - val_accuracy: 0.9273\nEpoch 302/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.4096 - accuracy: 0.8767 - val_loss: 0.3787 - val_accuracy: 0.9273\nEpoch 303/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.4085 - accuracy: 0.8767 - val_loss: 0.3778 - val_accuracy: 0.9273\nEpoch 304/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.4074 - accuracy: 0.8779 - val_loss: 0.3768 - val_accuracy: 0.9318\nEpoch 305/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.8790 - val_loss: 0.3757 - val_accuracy: 0.9318\nEpoch 306/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.4050 - accuracy: 0.8790 - val_loss: 0.3747 - val_accuracy: 0.9364\nEpoch 307/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8813 - val_loss: 0.3735 - val_accuracy: 0.9364\nEpoch 308/700\n18/18 [==============================] - 1s 30ms/step - loss: 0.4028 - accuracy: 0.8813 - val_loss: 0.3723 - val_accuracy: 0.9364\nEpoch 309/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.4017 - accuracy: 0.8824 - val_loss: 0.3713 - val_accuracy: 0.9364\nEpoch 310/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.8813 - val_loss: 0.3700 - val_accuracy: 0.9364\nEpoch 311/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3994 - accuracy: 0.8813 - val_loss: 0.3690 - val_accuracy: 0.9364\nEpoch 312/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.3982 - accuracy: 0.8847 - val_loss: 0.3678 - val_accuracy: 0.9364\nEpoch 313/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.3971 - accuracy: 0.8824 - val_loss: 0.3666 - val_accuracy: 0.9364\nEpoch 314/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.3960 - accuracy: 0.8847 - val_loss: 0.3654 - val_accuracy: 0.9364\nEpoch 315/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.3949 - accuracy: 0.8847 - val_loss: 0.3645 - val_accuracy: 0.9364\nEpoch 316/700\n18/18 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.88 - 0s 9ms/step - loss: 0.3937 - accuracy: 0.8847 - val_loss: 0.3634 - val_accuracy: 0.9364\nEpoch 317/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.3926 - accuracy: 0.8847 - val_loss: 0.3626 - val_accuracy: 0.9364\nEpoch 318/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.8858 - val_loss: 0.3611 - val_accuracy: 0.9364\nEpoch 319/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3904 - accuracy: 0.8858 - val_loss: 0.3600 - val_accuracy: 0.9364\nEpoch 320/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3892 - accuracy: 0.8847 - val_loss: 0.3593 - val_accuracy: 0.9364\nEpoch 321/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8858 - val_loss: 0.3584 - val_accuracy: 0.9364\nEpoch 322/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.8870 - val_loss: 0.3570 - val_accuracy: 0.9364\nEpoch 323/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3859 - accuracy: 0.8870 - val_loss: 0.3562 - val_accuracy: 0.9364\nEpoch 324/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8881 - val_loss: 0.3550 - val_accuracy: 0.9364\nEpoch 325/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3837 - accuracy: 0.8870 - val_loss: 0.3543 - val_accuracy: 0.9364\nEpoch 326/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3825 - accuracy: 0.8881 - val_loss: 0.3530 - val_accuracy: 0.9364\nEpoch 327/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3814 - accuracy: 0.8893 - val_loss: 0.3516 - val_accuracy: 0.9364\nEpoch 328/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.8881 - val_loss: 0.3505 - val_accuracy: 0.9364\nEpoch 329/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.3792 - accuracy: 0.8904 - val_loss: 0.3495 - val_accuracy: 0.9364\nEpoch 330/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3781 - accuracy: 0.8893 - val_loss: 0.3484 - val_accuracy: 0.9364\nEpoch 331/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8893 - val_loss: 0.3475 - val_accuracy: 0.9364\nEpoch 332/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.8916 - val_loss: 0.3470 - val_accuracy: 0.9364\nEpoch 333/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.8973 - val_loss: 0.3458 - val_accuracy: 0.9364\nEpoch 334/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8961 - val_loss: 0.3446 - val_accuracy: 0.9364\nEpoch 335/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.8938 - val_loss: 0.3435 - val_accuracy: 0.9364\nEpoch 336/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.3716 - accuracy: 0.8950 - val_loss: 0.3424 - val_accuracy: 0.9364\nEpoch 337/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3703 - accuracy: 0.8973 - val_loss: 0.3413 - val_accuracy: 0.9364\nEpoch 338/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3692 - accuracy: 0.8984 - val_loss: 0.3400 - val_accuracy: 0.9364\nEpoch 339/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8973 - val_loss: 0.3391 - val_accuracy: 0.9364\nEpoch 340/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.8984 - val_loss: 0.3381 - val_accuracy: 0.9364\nEpoch 341/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3660 - accuracy: 0.8973 - val_loss: 0.3371 - val_accuracy: 0.9364\nEpoch 342/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3649 - accuracy: 0.8973 - val_loss: 0.3362 - val_accuracy: 0.9364\nEpoch 343/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.9030 - val_loss: 0.3349 - val_accuracy: 0.9364\nEpoch 344/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3628 - accuracy: 0.8984 - val_loss: 0.3343 - val_accuracy: 0.9364\nEpoch 345/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3617 - accuracy: 0.9030 - val_loss: 0.3334 - val_accuracy: 0.9364\nEpoch 346/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.9041 - val_loss: 0.3319 - val_accuracy: 0.9364\nEpoch 347/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3596 - accuracy: 0.9018 - val_loss: 0.3310 - val_accuracy: 0.9364\nEpoch 348/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3585 - accuracy: 0.9041 - val_loss: 0.3297 - val_accuracy: 0.9364\nEpoch 349/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3574 - accuracy: 0.9041 - val_loss: 0.3288 - val_accuracy: 0.9364\nEpoch 350/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.3564 - accuracy: 0.9041 - val_loss: 0.3278 - val_accuracy: 0.9364\nEpoch 351/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.3552 - accuracy: 0.9053 - val_loss: 0.3269 - val_accuracy: 0.9364\nEpoch 352/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.3542 - accuracy: 0.9053 - val_loss: 0.3260 - val_accuracy: 0.9364\nEpoch 353/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.9075 - val_loss: 0.3249 - val_accuracy: 0.9364\nEpoch 354/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.3521 - accuracy: 0.9064 - val_loss: 0.3239 - val_accuracy: 0.9364\nEpoch 355/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.9075 - val_loss: 0.3227 - val_accuracy: 0.9364\nEpoch 356/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3500 - accuracy: 0.9053 - val_loss: 0.3218 - val_accuracy: 0.9364\nEpoch 357/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.9087 - val_loss: 0.3205 - val_accuracy: 0.9364\nEpoch 358/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3479 - accuracy: 0.9075 - val_loss: 0.3195 - val_accuracy: 0.9364\nEpoch 359/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.3468 - accuracy: 0.9087 - val_loss: 0.3187 - val_accuracy: 0.9364\nEpoch 360/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.3458 - accuracy: 0.9098 - val_loss: 0.3179 - val_accuracy: 0.9364\nEpoch 361/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3448 - accuracy: 0.9110 - val_loss: 0.3170 - val_accuracy: 0.9364\nEpoch 362/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3437 - accuracy: 0.9098 - val_loss: 0.3162 - val_accuracy: 0.9364\nEpoch 363/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.3427 - accuracy: 0.9121 - val_loss: 0.3154 - val_accuracy: 0.9364\nEpoch 364/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3416 - accuracy: 0.9144 - val_loss: 0.3141 - val_accuracy: 0.9364\nEpoch 365/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3406 - accuracy: 0.9132 - val_loss: 0.3129 - val_accuracy: 0.9364\nEpoch 366/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.9144 - val_loss: 0.3122 - val_accuracy: 0.9364\nEpoch 367/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.9155 - val_loss: 0.3109 - val_accuracy: 0.9364\nEpoch 368/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.9144 - val_loss: 0.3099 - val_accuracy: 0.9364\nEpoch 369/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.9155 - val_loss: 0.3090 - val_accuracy: 0.9364\nEpoch 370/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3354 - accuracy: 0.9144 - val_loss: 0.3083 - val_accuracy: 0.9364\nEpoch 371/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3344 - accuracy: 0.9178 - val_loss: 0.3069 - val_accuracy: 0.9364\nEpoch 372/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3334 - accuracy: 0.9167 - val_loss: 0.3062 - val_accuracy: 0.9409\nEpoch 373/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3324 - accuracy: 0.9189 - val_loss: 0.3050 - val_accuracy: 0.9364\nEpoch 374/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.3313 - accuracy: 0.9178 - val_loss: 0.3043 - val_accuracy: 0.9409\nEpoch 375/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.9189 - val_loss: 0.3033 - val_accuracy: 0.9409\nEpoch 376/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3293 - accuracy: 0.9178 - val_loss: 0.3026 - val_accuracy: 0.9409\nEpoch 377/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3285 - accuracy: 0.9201 - val_loss: 0.3014 - val_accuracy: 0.9409\nEpoch 378/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3274 - accuracy: 0.9189 - val_loss: 0.3004 - val_accuracy: 0.9409\nEpoch 379/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3265 - accuracy: 0.9189 - val_loss: 0.2999 - val_accuracy: 0.9409\nEpoch 380/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 0.9247 - val_loss: 0.2988 - val_accuracy: 0.9409\nEpoch 381/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.3243 - accuracy: 0.9212 - val_loss: 0.2980 - val_accuracy: 0.9409\nEpoch 382/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.3234 - accuracy: 0.9235 - val_loss: 0.2971 - val_accuracy: 0.9409\nEpoch 383/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.3225 - accuracy: 0.9247 - val_loss: 0.2962 - val_accuracy: 0.9409\nEpoch 384/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3214 - accuracy: 0.9258 - val_loss: 0.2950 - val_accuracy: 0.9409\nEpoch 385/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3204 - accuracy: 0.9281 - val_loss: 0.2940 - val_accuracy: 0.9409\nEpoch 386/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.9258 - val_loss: 0.2930 - val_accuracy: 0.9409\nEpoch 387/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3185 - accuracy: 0.9247 - val_loss: 0.2923 - val_accuracy: 0.9409\nEpoch 388/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.9304 - val_loss: 0.2913 - val_accuracy: 0.9409\nEpoch 389/700\n18/18 [==============================] - 0s 6ms/step - loss: 0.3166 - accuracy: 0.9292 - val_loss: 0.2906 - val_accuracy: 0.9409\nEpoch 390/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.3156 - accuracy: 0.9304 - val_loss: 0.2894 - val_accuracy: 0.9409\nEpoch 391/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3147 - accuracy: 0.9304 - val_loss: 0.2885 - val_accuracy: 0.9409\nEpoch 392/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.3137 - accuracy: 0.9269 - val_loss: 0.2878 - val_accuracy: 0.9455\nEpoch 393/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.9304 - val_loss: 0.2866 - val_accuracy: 0.9409\nEpoch 394/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.3117 - accuracy: 0.9304 - val_loss: 0.2859 - val_accuracy: 0.9455\nEpoch 395/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.3109 - accuracy: 0.9304 - val_loss: 0.2852 - val_accuracy: 0.9455\nEpoch 396/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3099 - accuracy: 0.9304 - val_loss: 0.2843 - val_accuracy: 0.9455\nEpoch 397/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.3089 - accuracy: 0.9304 - val_loss: 0.2831 - val_accuracy: 0.9455\nEpoch 398/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.3081 - accuracy: 0.9304 - val_loss: 0.2826 - val_accuracy: 0.9500\nEpoch 399/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.3071 - accuracy: 0.9304 - val_loss: 0.2821 - val_accuracy: 0.9500\nEpoch 400/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3061 - accuracy: 0.9304 - val_loss: 0.2808 - val_accuracy: 0.9500\nEpoch 401/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3052 - accuracy: 0.9304 - val_loss: 0.2799 - val_accuracy: 0.9500\nEpoch 402/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.3043 - accuracy: 0.9304 - val_loss: 0.2789 - val_accuracy: 0.9500\nEpoch 403/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.3033 - accuracy: 0.9304 - val_loss: 0.2781 - val_accuracy: 0.9500\nEpoch 404/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.3024 - accuracy: 0.9315 - val_loss: 0.2772 - val_accuracy: 0.9500\nEpoch 405/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.3015 - accuracy: 0.9315 - val_loss: 0.2760 - val_accuracy: 0.9500\nEpoch 406/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.9304 - val_loss: 0.2753 - val_accuracy: 0.9500\nEpoch 407/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.2997 - accuracy: 0.9304 - val_loss: 0.2745 - val_accuracy: 0.9500\nEpoch 408/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2988 - accuracy: 0.9315 - val_loss: 0.2736 - val_accuracy: 0.9500\nEpoch 409/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.2979 - accuracy: 0.9315 - val_loss: 0.2726 - val_accuracy: 0.9500\nEpoch 410/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.9315 - val_loss: 0.2719 - val_accuracy: 0.9500\nEpoch 411/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2960 - accuracy: 0.9315 - val_loss: 0.2709 - val_accuracy: 0.9500\nEpoch 412/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2952 - accuracy: 0.9315 - val_loss: 0.2699 - val_accuracy: 0.9500\nEpoch 413/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 0.9315 - val_loss: 0.2690 - val_accuracy: 0.9500\nEpoch 414/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2935 - accuracy: 0.9315 - val_loss: 0.2684 - val_accuracy: 0.9545\nEpoch 415/700\n18/18 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.92 - 0s 13ms/step - loss: 0.2924 - accuracy: 0.9315 - val_loss: 0.2675 - val_accuracy: 0.9545\nEpoch 416/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2916 - accuracy: 0.9315 - val_loss: 0.2670 - val_accuracy: 0.9591\nEpoch 417/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2906 - accuracy: 0.9315 - val_loss: 0.2660 - val_accuracy: 0.9591\nEpoch 418/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2898 - accuracy: 0.9315 - val_loss: 0.2651 - val_accuracy: 0.9591\nEpoch 419/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2889 - accuracy: 0.9315 - val_loss: 0.2644 - val_accuracy: 0.9591\nEpoch 420/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.2880 - accuracy: 0.9315 - val_loss: 0.2632 - val_accuracy: 0.9591\nEpoch 421/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.2872 - accuracy: 0.9315 - val_loss: 0.2624 - val_accuracy: 0.9591\nEpoch 422/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.2863 - accuracy: 0.9315 - val_loss: 0.2616 - val_accuracy: 0.9591\nEpoch 423/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2855 - accuracy: 0.9315 - val_loss: 0.2611 - val_accuracy: 0.9636\nEpoch 424/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2846 - accuracy: 0.9315 - val_loss: 0.2602 - val_accuracy: 0.9636\nEpoch 425/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2838 - accuracy: 0.9326 - val_loss: 0.2591 - val_accuracy: 0.9591\nEpoch 426/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2829 - accuracy: 0.9315 - val_loss: 0.2583 - val_accuracy: 0.9636\nEpoch 427/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2820 - accuracy: 0.9326 - val_loss: 0.2580 - val_accuracy: 0.9636\nEpoch 428/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2812 - accuracy: 0.9338 - val_loss: 0.2574 - val_accuracy: 0.9636\nEpoch 429/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 0.9349 - val_loss: 0.2567 - val_accuracy: 0.9636\nEpoch 430/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2795 - accuracy: 0.9326 - val_loss: 0.2558 - val_accuracy: 0.9636\nEpoch 431/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2786 - accuracy: 0.9349 - val_loss: 0.2550 - val_accuracy: 0.9636\nEpoch 432/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2778 - accuracy: 0.9349 - val_loss: 0.2541 - val_accuracy: 0.9636\nEpoch 433/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2769 - accuracy: 0.9349 - val_loss: 0.2531 - val_accuracy: 0.9636\nEpoch 434/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2760 - accuracy: 0.9361 - val_loss: 0.2521 - val_accuracy: 0.9636\nEpoch 435/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2753 - accuracy: 0.9349 - val_loss: 0.2512 - val_accuracy: 0.9636\nEpoch 436/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2744 - accuracy: 0.9349 - val_loss: 0.2506 - val_accuracy: 0.9636\nEpoch 437/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2736 - accuracy: 0.9372 - val_loss: 0.2499 - val_accuracy: 0.9636\nEpoch 438/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2728 - accuracy: 0.9361 - val_loss: 0.2491 - val_accuracy: 0.9636\nEpoch 439/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2719 - accuracy: 0.9372 - val_loss: 0.2484 - val_accuracy: 0.9636\nEpoch 440/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.2711 - accuracy: 0.9372 - val_loss: 0.2481 - val_accuracy: 0.9636\nEpoch 441/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.2704 - accuracy: 0.9384 - val_loss: 0.2473 - val_accuracy: 0.9636\nEpoch 442/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2695 - accuracy: 0.9395 - val_loss: 0.2463 - val_accuracy: 0.9636\nEpoch 443/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2687 - accuracy: 0.9384 - val_loss: 0.2457 - val_accuracy: 0.9636\nEpoch 444/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.2679 - accuracy: 0.9395 - val_loss: 0.2449 - val_accuracy: 0.9636\nEpoch 445/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2671 - accuracy: 0.9395 - val_loss: 0.2437 - val_accuracy: 0.9636\nEpoch 446/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2663 - accuracy: 0.9361 - val_loss: 0.2430 - val_accuracy: 0.9636\nEpoch 447/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2654 - accuracy: 0.9395 - val_loss: 0.2426 - val_accuracy: 0.9636\nEpoch 448/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2647 - accuracy: 0.9395 - val_loss: 0.2419 - val_accuracy: 0.9636\nEpoch 449/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9395 - val_loss: 0.2411 - val_accuracy: 0.9636\nEpoch 450/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2631 - accuracy: 0.9395 - val_loss: 0.2403 - val_accuracy: 0.9636\nEpoch 451/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2623 - accuracy: 0.9395 - val_loss: 0.2395 - val_accuracy: 0.9636\nEpoch 452/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2615 - accuracy: 0.9395 - val_loss: 0.2390 - val_accuracy: 0.9636\nEpoch 453/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2608 - accuracy: 0.9395 - val_loss: 0.2381 - val_accuracy: 0.9636\nEpoch 454/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2599 - accuracy: 0.9395 - val_loss: 0.2375 - val_accuracy: 0.9682\nEpoch 455/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2592 - accuracy: 0.9395 - val_loss: 0.2369 - val_accuracy: 0.9727\nEpoch 456/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2584 - accuracy: 0.9395 - val_loss: 0.2364 - val_accuracy: 0.9727\nEpoch 457/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2577 - accuracy: 0.9395 - val_loss: 0.2356 - val_accuracy: 0.9727\nEpoch 458/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.9395 - val_loss: 0.2347 - val_accuracy: 0.9727\nEpoch 459/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2562 - accuracy: 0.9395 - val_loss: 0.2339 - val_accuracy: 0.9727\nEpoch 460/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2554 - accuracy: 0.9395 - val_loss: 0.2331 - val_accuracy: 0.9727\nEpoch 461/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.2546 - accuracy: 0.9395 - val_loss: 0.2324 - val_accuracy: 0.9727\nEpoch 462/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2538 - accuracy: 0.9395 - val_loss: 0.2314 - val_accuracy: 0.9727\nEpoch 463/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 0.9395 - val_loss: 0.2305 - val_accuracy: 0.9727\nEpoch 464/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2523 - accuracy: 0.9395 - val_loss: 0.2299 - val_accuracy: 0.9727\nEpoch 465/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2516 - accuracy: 0.9395 - val_loss: 0.2295 - val_accuracy: 0.9727\nEpoch 466/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2508 - accuracy: 0.9395 - val_loss: 0.2289 - val_accuracy: 0.9727\nEpoch 467/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.9395 - val_loss: 0.2281 - val_accuracy: 0.9727\nEpoch 468/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2493 - accuracy: 0.9395 - val_loss: 0.2273 - val_accuracy: 0.9727\nEpoch 469/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.9395 - val_loss: 0.2267 - val_accuracy: 0.9727\nEpoch 470/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2479 - accuracy: 0.9395 - val_loss: 0.2260 - val_accuracy: 0.9727\nEpoch 471/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2471 - accuracy: 0.9406 - val_loss: 0.2251 - val_accuracy: 0.9727\nEpoch 472/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2464 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9727\nEpoch 473/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2456 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9727\nEpoch 474/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2449 - accuracy: 0.9395 - val_loss: 0.2231 - val_accuracy: 0.9727\nEpoch 475/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.2441 - accuracy: 0.9395 - val_loss: 0.2224 - val_accuracy: 0.9727\nEpoch 476/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.2435 - accuracy: 0.9406 - val_loss: 0.2220 - val_accuracy: 0.9727\nEpoch 477/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2427 - accuracy: 0.9406 - val_loss: 0.2211 - val_accuracy: 0.9727\nEpoch 478/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2420 - accuracy: 0.9406 - val_loss: 0.2203 - val_accuracy: 0.9727\nEpoch 479/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2413 - accuracy: 0.9406 - val_loss: 0.2199 - val_accuracy: 0.9727\nEpoch 480/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9406 - val_loss: 0.2190 - val_accuracy: 0.9727\nEpoch 481/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2398 - accuracy: 0.9406 - val_loss: 0.2182 - val_accuracy: 0.9727\nEpoch 482/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.9418 - val_loss: 0.2177 - val_accuracy: 0.9727\nEpoch 483/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2384 - accuracy: 0.9406 - val_loss: 0.2174 - val_accuracy: 0.9727\nEpoch 484/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2377 - accuracy: 0.9429 - val_loss: 0.2165 - val_accuracy: 0.9727\nEpoch 485/700\n18/18 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.9429 - val_loss: 0.2156 - val_accuracy: 0.9727\nEpoch 486/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2362 - accuracy: 0.9418 - val_loss: 0.2152 - val_accuracy: 0.9727\nEpoch 487/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2355 - accuracy: 0.9429 - val_loss: 0.2144 - val_accuracy: 0.9727\nEpoch 488/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2349 - accuracy: 0.9429 - val_loss: 0.2136 - val_accuracy: 0.9727\nEpoch 489/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9429 - val_loss: 0.2126 - val_accuracy: 0.9727\nEpoch 490/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2335 - accuracy: 0.9429 - val_loss: 0.2122 - val_accuracy: 0.9727\nEpoch 491/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2328 - accuracy: 0.9429 - val_loss: 0.2114 - val_accuracy: 0.9727\nEpoch 492/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2321 - accuracy: 0.9429 - val_loss: 0.2111 - val_accuracy: 0.9727\nEpoch 493/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9429 - val_loss: 0.2106 - val_accuracy: 0.9727\nEpoch 494/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9441 - val_loss: 0.2099 - val_accuracy: 0.9727\nEpoch 495/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2300 - accuracy: 0.9441 - val_loss: 0.2089 - val_accuracy: 0.9727\nEpoch 496/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2294 - accuracy: 0.9429 - val_loss: 0.2082 - val_accuracy: 0.9727\nEpoch 497/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.2286 - accuracy: 0.9441 - val_loss: 0.2077 - val_accuracy: 0.9727\nEpoch 498/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2280 - accuracy: 0.9429 - val_loss: 0.2069 - val_accuracy: 0.9727\nEpoch 499/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2273 - accuracy: 0.9441 - val_loss: 0.2065 - val_accuracy: 0.9727\nEpoch 500/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.2266 - accuracy: 0.9441 - val_loss: 0.2063 - val_accuracy: 0.9727\nEpoch 501/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.9452 - val_loss: 0.2057 - val_accuracy: 0.9727\nEpoch 502/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.9452 - val_loss: 0.2050 - val_accuracy: 0.9727\nEpoch 503/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2246 - accuracy: 0.9463 - val_loss: 0.2044 - val_accuracy: 0.9727\nEpoch 504/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2239 - accuracy: 0.9452 - val_loss: 0.2036 - val_accuracy: 0.9727\nEpoch 505/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.9452 - val_loss: 0.2030 - val_accuracy: 0.9727\nEpoch 506/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2226 - accuracy: 0.9463 - val_loss: 0.2023 - val_accuracy: 0.9727\nEpoch 507/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.2219 - accuracy: 0.9463 - val_loss: 0.2017 - val_accuracy: 0.9727\nEpoch 508/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2212 - accuracy: 0.9463 - val_loss: 0.2010 - val_accuracy: 0.9727\nEpoch 509/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2206 - accuracy: 0.9463 - val_loss: 0.2006 - val_accuracy: 0.9682\nEpoch 510/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2199 - accuracy: 0.9463 - val_loss: 0.1999 - val_accuracy: 0.9727\nEpoch 511/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9475 - val_loss: 0.1993 - val_accuracy: 0.9682\nEpoch 512/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2186 - accuracy: 0.9463 - val_loss: 0.1986 - val_accuracy: 0.9727\nEpoch 513/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.2180 - accuracy: 0.9463 - val_loss: 0.1978 - val_accuracy: 0.9727\nEpoch 514/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.9475 - val_loss: 0.1971 - val_accuracy: 0.9727\nEpoch 515/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2166 - accuracy: 0.9475 - val_loss: 0.1966 - val_accuracy: 0.9727\nEpoch 516/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2160 - accuracy: 0.9475 - val_loss: 0.1961 - val_accuracy: 0.9682\nEpoch 517/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2154 - accuracy: 0.9475 - val_loss: 0.1960 - val_accuracy: 0.9682\nEpoch 518/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.2147 - accuracy: 0.9475 - val_loss: 0.1953 - val_accuracy: 0.9682\nEpoch 519/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.2141 - accuracy: 0.9486 - val_loss: 0.1946 - val_accuracy: 0.9682\nEpoch 520/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2134 - accuracy: 0.9486 - val_loss: 0.1941 - val_accuracy: 0.9682\nEpoch 521/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.2128 - accuracy: 0.9486 - val_loss: 0.1935 - val_accuracy: 0.9682\nEpoch 522/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.2122 - accuracy: 0.9486 - val_loss: 0.1929 - val_accuracy: 0.9682\nEpoch 523/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2116 - accuracy: 0.9486 - val_loss: 0.1922 - val_accuracy: 0.9682\nEpoch 524/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2109 - accuracy: 0.9486 - val_loss: 0.1915 - val_accuracy: 0.9682\nEpoch 525/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2103 - accuracy: 0.9475 - val_loss: 0.1912 - val_accuracy: 0.9682\nEpoch 526/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2097 - accuracy: 0.9509 - val_loss: 0.1904 - val_accuracy: 0.9682\nEpoch 527/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.2090 - accuracy: 0.9509 - val_loss: 0.1899 - val_accuracy: 0.9682\nEpoch 528/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.2084 - accuracy: 0.9509 - val_loss: 0.1892 - val_accuracy: 0.9682\nEpoch 529/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.2078 - accuracy: 0.9509 - val_loss: 0.1886 - val_accuracy: 0.9682\nEpoch 530/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.2072 - accuracy: 0.9509 - val_loss: 0.1879 - val_accuracy: 0.9682\nEpoch 531/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.2065 - accuracy: 0.9509 - val_loss: 0.1875 - val_accuracy: 0.9682\nEpoch 532/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2059 - accuracy: 0.9509 - val_loss: 0.1869 - val_accuracy: 0.9682\nEpoch 533/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.2054 - accuracy: 0.9509 - val_loss: 0.1863 - val_accuracy: 0.9682\nEpoch 534/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.2048 - accuracy: 0.9509 - val_loss: 0.1858 - val_accuracy: 0.9682\nEpoch 535/700\n18/18 [==============================] - 0s 26ms/step - loss: 0.2041 - accuracy: 0.9509 - val_loss: 0.1851 - val_accuracy: 0.9682\nEpoch 536/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.2034 - accuracy: 0.9521 - val_loss: 0.1848 - val_accuracy: 0.9682\nEpoch 537/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.9509 - val_loss: 0.1841 - val_accuracy: 0.9682\nEpoch 538/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.2022 - accuracy: 0.9521 - val_loss: 0.1835 - val_accuracy: 0.9682\nEpoch 539/700\n18/18 [==============================] - 0s 27ms/step - loss: 0.2016 - accuracy: 0.9532 - val_loss: 0.1830 - val_accuracy: 0.9682\nEpoch 540/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.2011 - accuracy: 0.9521 - val_loss: 0.1824 - val_accuracy: 0.9682\nEpoch 541/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.2004 - accuracy: 0.9532 - val_loss: 0.1821 - val_accuracy: 0.9682\nEpoch 542/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1998 - accuracy: 0.9509 - val_loss: 0.1815 - val_accuracy: 0.9682\nEpoch 543/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1993 - accuracy: 0.9532 - val_loss: 0.1807 - val_accuracy: 0.9682\nEpoch 544/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1986 - accuracy: 0.9532 - val_loss: 0.1801 - val_accuracy: 0.9682\nEpoch 545/700\n18/18 [==============================] - 1s 35ms/step - loss: 0.1981 - accuracy: 0.9521 - val_loss: 0.1796 - val_accuracy: 0.9682\nEpoch 546/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1974 - accuracy: 0.9532 - val_loss: 0.1792 - val_accuracy: 0.9682\nEpoch 547/700\n18/18 [==============================] - 1s 29ms/step - loss: 0.1968 - accuracy: 0.9532 - val_loss: 0.1790 - val_accuracy: 0.9682\nEpoch 548/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1963 - accuracy: 0.9521 - val_loss: 0.1784 - val_accuracy: 0.9682\nEpoch 549/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1957 - accuracy: 0.9521 - val_loss: 0.1776 - val_accuracy: 0.9682\nEpoch 550/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.1951 - accuracy: 0.9532 - val_loss: 0.1768 - val_accuracy: 0.9682\nEpoch 551/700\n18/18 [==============================] - 1s 29ms/step - loss: 0.1945 - accuracy: 0.9532 - val_loss: 0.1765 - val_accuracy: 0.9682\nEpoch 552/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1940 - accuracy: 0.9543 - val_loss: 0.1761 - val_accuracy: 0.9682\nEpoch 553/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1934 - accuracy: 0.9543 - val_loss: 0.1754 - val_accuracy: 0.9682\nEpoch 554/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1928 - accuracy: 0.9543 - val_loss: 0.1747 - val_accuracy: 0.9682\nEpoch 555/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.1923 - accuracy: 0.9543 - val_loss: 0.1742 - val_accuracy: 0.9682\nEpoch 556/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1917 - accuracy: 0.9543 - val_loss: 0.1737 - val_accuracy: 0.9682\nEpoch 557/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1912 - accuracy: 0.9555 - val_loss: 0.1732 - val_accuracy: 0.9682\nEpoch 558/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1905 - accuracy: 0.9555 - val_loss: 0.1727 - val_accuracy: 0.9682\nEpoch 559/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1900 - accuracy: 0.9555 - val_loss: 0.1723 - val_accuracy: 0.9682\nEpoch 560/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1895 - accuracy: 0.9555 - val_loss: 0.1719 - val_accuracy: 0.9682\nEpoch 561/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1889 - accuracy: 0.9566 - val_loss: 0.1715 - val_accuracy: 0.9682\nEpoch 562/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1884 - accuracy: 0.9555 - val_loss: 0.1710 - val_accuracy: 0.9682\nEpoch 563/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1705 - val_accuracy: 0.9682\nEpoch 564/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 0.9555 - val_loss: 0.1701 - val_accuracy: 0.9682\nEpoch 565/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1867 - accuracy: 0.9566 - val_loss: 0.1695 - val_accuracy: 0.9682\nEpoch 566/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1862 - accuracy: 0.9566 - val_loss: 0.1689 - val_accuracy: 0.9682\nEpoch 567/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1857 - accuracy: 0.9566 - val_loss: 0.1687 - val_accuracy: 0.9682\nEpoch 568/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1852 - accuracy: 0.9566 - val_loss: 0.1680 - val_accuracy: 0.9682\nEpoch 569/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.1847 - accuracy: 0.9566 - val_loss: 0.1674 - val_accuracy: 0.9682\nEpoch 570/700\n18/18 [==============================] - 0s 8ms/step - loss: 0.1841 - accuracy: 0.9566 - val_loss: 0.1671 - val_accuracy: 0.9682\nEpoch 571/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9566 - val_loss: 0.1666 - val_accuracy: 0.9682\nEpoch 572/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1830 - accuracy: 0.9566 - val_loss: 0.1663 - val_accuracy: 0.9682\nEpoch 573/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1825 - accuracy: 0.9566 - val_loss: 0.1658 - val_accuracy: 0.9682\nEpoch 574/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1820 - accuracy: 0.9566 - val_loss: 0.1653 - val_accuracy: 0.9682\nEpoch 575/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1815 - accuracy: 0.9566 - val_loss: 0.1649 - val_accuracy: 0.9682\nEpoch 576/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.1810 - accuracy: 0.9566 - val_loss: 0.1644 - val_accuracy: 0.9682\nEpoch 577/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1805 - accuracy: 0.9566 - val_loss: 0.1640 - val_accuracy: 0.9682\nEpoch 578/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1799 - accuracy: 0.9566 - val_loss: 0.1634 - val_accuracy: 0.9682\nEpoch 579/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1795 - accuracy: 0.9566 - val_loss: 0.1633 - val_accuracy: 0.9682\nEpoch 580/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1790 - accuracy: 0.9566 - val_loss: 0.1627 - val_accuracy: 0.9682\nEpoch 581/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1785 - accuracy: 0.9555 - val_loss: 0.1621 - val_accuracy: 0.9682\nEpoch 582/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1779 - accuracy: 0.9578 - val_loss: 0.1615 - val_accuracy: 0.9682\nEpoch 583/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1774 - accuracy: 0.9578 - val_loss: 0.1613 - val_accuracy: 0.9682\nEpoch 584/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1770 - accuracy: 0.9578 - val_loss: 0.1608 - val_accuracy: 0.9682\nEpoch 585/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1764 - accuracy: 0.9578 - val_loss: 0.1604 - val_accuracy: 0.9682\nEpoch 586/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1759 - accuracy: 0.9578 - val_loss: 0.1600 - val_accuracy: 0.9682\nEpoch 587/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1755 - accuracy: 0.9578 - val_loss: 0.1597 - val_accuracy: 0.9636\nEpoch 588/700\n18/18 [==============================] - 0s 25ms/step - loss: 0.1749 - accuracy: 0.9578 - val_loss: 0.1589 - val_accuracy: 0.9682\nEpoch 589/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1745 - accuracy: 0.9566 - val_loss: 0.1585 - val_accuracy: 0.9682\nEpoch 590/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1740 - accuracy: 0.9578 - val_loss: 0.1580 - val_accuracy: 0.9682\nEpoch 591/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1735 - accuracy: 0.9578 - val_loss: 0.1576 - val_accuracy: 0.9682\nEpoch 592/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1730 - accuracy: 0.9578 - val_loss: 0.1574 - val_accuracy: 0.9636\nEpoch 593/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1725 - accuracy: 0.9589 - val_loss: 0.1568 - val_accuracy: 0.9636\nEpoch 594/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1721 - accuracy: 0.9600 - val_loss: 0.1562 - val_accuracy: 0.9682\nEpoch 595/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1716 - accuracy: 0.9589 - val_loss: 0.1559 - val_accuracy: 0.9636\nEpoch 596/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1711 - accuracy: 0.9589 - val_loss: 0.1555 - val_accuracy: 0.9636\nEpoch 597/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1706 - accuracy: 0.9589 - val_loss: 0.1551 - val_accuracy: 0.9636\nEpoch 598/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1702 - accuracy: 0.9589 - val_loss: 0.1547 - val_accuracy: 0.9636\nEpoch 599/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1696 - accuracy: 0.9589 - val_loss: 0.1543 - val_accuracy: 0.9636\nEpoch 600/700\n18/18 [==============================] - 1s 35ms/step - loss: 0.1692 - accuracy: 0.9589 - val_loss: 0.1538 - val_accuracy: 0.9636\nEpoch 601/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1687 - accuracy: 0.9589 - val_loss: 0.1536 - val_accuracy: 0.9636\nEpoch 602/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1683 - accuracy: 0.9589 - val_loss: 0.1531 - val_accuracy: 0.9636\nEpoch 603/700\n18/18 [==============================] - 1s 30ms/step - loss: 0.1679 - accuracy: 0.9589 - val_loss: 0.1528 - val_accuracy: 0.9636\nEpoch 604/700\n18/18 [==============================] - 1s 28ms/step - loss: 0.1674 - accuracy: 0.9600 - val_loss: 0.1521 - val_accuracy: 0.9636\nEpoch 605/700\n18/18 [==============================] - 0s 11ms/step - loss: 0.1669 - accuracy: 0.9589 - val_loss: 0.1518 - val_accuracy: 0.9636\nEpoch 606/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1664 - accuracy: 0.9589 - val_loss: 0.1515 - val_accuracy: 0.9636\nEpoch 607/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1659 - accuracy: 0.9589 - val_loss: 0.1510 - val_accuracy: 0.9636\nEpoch 608/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9589 - val_loss: 0.1507 - val_accuracy: 0.9636\nEpoch 609/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1650 - accuracy: 0.9600 - val_loss: 0.1500 - val_accuracy: 0.9636\nEpoch 610/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.9600 - val_loss: 0.1498 - val_accuracy: 0.9636\nEpoch 611/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1641 - accuracy: 0.9600 - val_loss: 0.1493 - val_accuracy: 0.9636\nEpoch 612/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1636 - accuracy: 0.9600 - val_loss: 0.1490 - val_accuracy: 0.9682\nEpoch 613/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1632 - accuracy: 0.9600 - val_loss: 0.1486 - val_accuracy: 0.9682\nEpoch 614/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9600 - val_loss: 0.1484 - val_accuracy: 0.9682\nEpoch 615/700\n18/18 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.96 - 0s 19ms/step - loss: 0.1623 - accuracy: 0.9612 - val_loss: 0.1480 - val_accuracy: 0.9682\nEpoch 616/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1618 - accuracy: 0.9612 - val_loss: 0.1475 - val_accuracy: 0.9682\nEpoch 617/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.1471 - val_accuracy: 0.9682\nEpoch 618/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.1609 - accuracy: 0.9623 - val_loss: 0.1468 - val_accuracy: 0.9727\nEpoch 619/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1605 - accuracy: 0.9612 - val_loss: 0.1463 - val_accuracy: 0.9682\nEpoch 620/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1600 - accuracy: 0.9623 - val_loss: 0.1459 - val_accuracy: 0.9682\nEpoch 621/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9623 - val_loss: 0.1454 - val_accuracy: 0.9682\nEpoch 622/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1592 - accuracy: 0.9623 - val_loss: 0.1451 - val_accuracy: 0.9727\nEpoch 623/700\n18/18 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9635 - val_loss: 0.1447 - val_accuracy: 0.9727\nEpoch 624/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1583 - accuracy: 0.9635 - val_loss: 0.1445 - val_accuracy: 0.9727\nEpoch 625/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.1579 - accuracy: 0.9635 - val_loss: 0.1443 - val_accuracy: 0.9727\nEpoch 626/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1574 - accuracy: 0.9635 - val_loss: 0.1440 - val_accuracy: 0.9727\nEpoch 627/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1570 - accuracy: 0.9635 - val_loss: 0.1436 - val_accuracy: 0.9727\nEpoch 628/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1566 - accuracy: 0.9635 - val_loss: 0.1430 - val_accuracy: 0.9727\nEpoch 629/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1561 - accuracy: 0.9635 - val_loss: 0.1424 - val_accuracy: 0.9727\nEpoch 630/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1557 - accuracy: 0.9635 - val_loss: 0.1418 - val_accuracy: 0.9727\nEpoch 631/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1553 - accuracy: 0.9635 - val_loss: 0.1415 - val_accuracy: 0.9727\nEpoch 632/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1548 - accuracy: 0.9635 - val_loss: 0.1410 - val_accuracy: 0.9727\nEpoch 633/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1544 - accuracy: 0.9635 - val_loss: 0.1408 - val_accuracy: 0.9727\nEpoch 634/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1540 - accuracy: 0.9635 - val_loss: 0.1405 - val_accuracy: 0.9727\nEpoch 635/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1535 - accuracy: 0.9635 - val_loss: 0.1400 - val_accuracy: 0.9727\nEpoch 636/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1532 - accuracy: 0.9635 - val_loss: 0.1396 - val_accuracy: 0.9727\nEpoch 637/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1527 - accuracy: 0.9635 - val_loss: 0.1393 - val_accuracy: 0.9727\nEpoch 638/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1523 - accuracy: 0.9635 - val_loss: 0.1388 - val_accuracy: 0.9727\nEpoch 639/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1519 - accuracy: 0.9635 - val_loss: 0.1384 - val_accuracy: 0.9727\nEpoch 640/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1515 - accuracy: 0.9635 - val_loss: 0.1380 - val_accuracy: 0.9727\nEpoch 641/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1511 - accuracy: 0.9646 - val_loss: 0.1377 - val_accuracy: 0.9727\nEpoch 642/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1507 - accuracy: 0.9635 - val_loss: 0.1374 - val_accuracy: 0.9727\nEpoch 643/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1503 - accuracy: 0.9646 - val_loss: 0.1370 - val_accuracy: 0.9727\nEpoch 644/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1499 - accuracy: 0.9646 - val_loss: 0.1366 - val_accuracy: 0.9727\nEpoch 645/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1495 - accuracy: 0.9646 - val_loss: 0.1362 - val_accuracy: 0.9727\nEpoch 646/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1491 - accuracy: 0.9635 - val_loss: 0.1361 - val_accuracy: 0.9727\nEpoch 647/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1486 - accuracy: 0.9658 - val_loss: 0.1358 - val_accuracy: 0.9727\nEpoch 648/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1483 - accuracy: 0.9658 - val_loss: 0.1354 - val_accuracy: 0.9727\nEpoch 649/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9658 - val_loss: 0.1350 - val_accuracy: 0.9727\nEpoch 650/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1475 - accuracy: 0.9658 - val_loss: 0.1347 - val_accuracy: 0.9727\nEpoch 651/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1471 - accuracy: 0.9658 - val_loss: 0.1344 - val_accuracy: 0.9727\nEpoch 652/700\n18/18 [==============================] - 1s 33ms/step - loss: 0.1466 - accuracy: 0.9669 - val_loss: 0.1340 - val_accuracy: 0.9727\nEpoch 653/700\n18/18 [==============================] - 1s 62ms/step - loss: 0.1462 - accuracy: 0.9669 - val_loss: 0.1336 - val_accuracy: 0.9727\nEpoch 654/700\n18/18 [==============================] - 1s 49ms/step - loss: 0.1458 - accuracy: 0.9669 - val_loss: 0.1331 - val_accuracy: 0.9727s - loss: 0.1463 - accuracy: \nEpoch 655/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1455 - accuracy: 0.9680 - val_loss: 0.1328 - val_accuracy: 0.9727\nEpoch 656/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1451 - accuracy: 0.9669 - val_loss: 0.1325 - val_accuracy: 0.9727\nEpoch 657/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1447 - accuracy: 0.9669 - val_loss: 0.1323 - val_accuracy: 0.9727\nEpoch 658/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1443 - accuracy: 0.9680 - val_loss: 0.1322 - val_accuracy: 0.9727\nEpoch 659/700\n18/18 [==============================] - 0s 24ms/step - loss: 0.1439 - accuracy: 0.9692 - val_loss: 0.1317 - val_accuracy: 0.9727\nEpoch 660/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1435 - accuracy: 0.9680 - val_loss: 0.1313 - val_accuracy: 0.9727\nEpoch 661/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1431 - accuracy: 0.9692 - val_loss: 0.1308 - val_accuracy: 0.9727\nEpoch 662/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1428 - accuracy: 0.9680 - val_loss: 0.1304 - val_accuracy: 0.9727\nEpoch 663/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1423 - accuracy: 0.9703 - val_loss: 0.1301 - val_accuracy: 0.9727\nEpoch 664/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.9703 - val_loss: 0.1298 - val_accuracy: 0.9727\nEpoch 665/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1416 - accuracy: 0.9692 - val_loss: 0.1294 - val_accuracy: 0.9727\nEpoch 666/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1412 - accuracy: 0.9703 - val_loss: 0.1291 - val_accuracy: 0.9727\nEpoch 667/700\n18/18 [==============================] - 0s 25ms/step - loss: 0.1408 - accuracy: 0.9703 - val_loss: 0.1286 - val_accuracy: 0.9727\nEpoch 668/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9715 - val_loss: 0.1284 - val_accuracy: 0.9727\nEpoch 669/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1400 - accuracy: 0.9715 - val_loss: 0.1281 - val_accuracy: 0.9727\nEpoch 670/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1397 - accuracy: 0.9715 - val_loss: 0.1277 - val_accuracy: 0.9727\nEpoch 671/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1393 - accuracy: 0.9726 - val_loss: 0.1274 - val_accuracy: 0.9727\nEpoch 672/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1389 - accuracy: 0.9715 - val_loss: 0.1271 - val_accuracy: 0.9727\nEpoch 673/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1385 - accuracy: 0.9715 - val_loss: 0.1268 - val_accuracy: 0.9727\nEpoch 674/700\n18/18 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9715 - val_loss: 0.1264 - val_accuracy: 0.9727\nEpoch 675/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9726 - val_loss: 0.1261 - val_accuracy: 0.9727\nEpoch 676/700\n18/18 [==============================] - 0s 22ms/step - loss: 0.1374 - accuracy: 0.9737 - val_loss: 0.1258 - val_accuracy: 0.9727\nEpoch 677/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1370 - accuracy: 0.9737 - val_loss: 0.1256 - val_accuracy: 0.9727\nEpoch 678/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1367 - accuracy: 0.9737 - val_loss: 0.1254 - val_accuracy: 0.9727\nEpoch 679/700\n18/18 [==============================] - 0s 23ms/step - loss: 0.1363 - accuracy: 0.9737 - val_loss: 0.1249 - val_accuracy: 0.9727\nEpoch 680/700\n18/18 [==============================] - 0s 19ms/step - loss: 0.1359 - accuracy: 0.9737 - val_loss: 0.1244 - val_accuracy: 0.9727\nEpoch 681/700\n18/18 [==============================] - 0s 21ms/step - loss: 0.1355 - accuracy: 0.9726 - val_loss: 0.1242 - val_accuracy: 0.9727\nEpoch 682/700\n18/18 [==============================] - 0s 27ms/step - loss: 0.1352 - accuracy: 0.9737 - val_loss: 0.1239 - val_accuracy: 0.9727\nEpoch 683/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1348 - accuracy: 0.9737 - val_loss: 0.1235 - val_accuracy: 0.9727\nEpoch 684/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1344 - accuracy: 0.9737 - val_loss: 0.1230 - val_accuracy: 0.9727\nEpoch 685/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1341 - accuracy: 0.9737 - val_loss: 0.1228 - val_accuracy: 0.9727\nEpoch 686/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1337 - accuracy: 0.9737 - val_loss: 0.1225 - val_accuracy: 0.9727\nEpoch 687/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1333 - accuracy: 0.9737 - val_loss: 0.1221 - val_accuracy: 0.9727\nEpoch 688/700\n18/18 [==============================] - 0s 17ms/step - loss: 0.1329 - accuracy: 0.9737 - val_loss: 0.1216 - val_accuracy: 0.9727\nEpoch 689/700\n18/18 [==============================] - 0s 13ms/step - loss: 0.1325 - accuracy: 0.9737 - val_loss: 0.1214 - val_accuracy: 0.9727\nEpoch 690/700\n18/18 [==============================] - 0s 20ms/step - loss: 0.1322 - accuracy: 0.9737 - val_loss: 0.1211 - val_accuracy: 0.9727\nEpoch 691/700\n18/18 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.97 - 0s 17ms/step - loss: 0.1319 - accuracy: 0.9737 - val_loss: 0.1208 - val_accuracy: 0.9727\nEpoch 692/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1315 - accuracy: 0.9737 - val_loss: 0.1205 - val_accuracy: 0.9727\nEpoch 693/700\n18/18 [==============================] - 0s 15ms/step - loss: 0.1312 - accuracy: 0.9737 - val_loss: 0.1202 - val_accuracy: 0.9727\nEpoch 694/700\n18/18 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.97 - 0s 17ms/step - loss: 0.1308 - accuracy: 0.9737 - val_loss: 0.1198 - val_accuracy: 0.9727\nEpoch 695/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1305 - accuracy: 0.9737 - val_loss: 0.1193 - val_accuracy: 0.9727\nEpoch 696/700\n18/18 [==============================] - 0s 12ms/step - loss: 0.1302 - accuracy: 0.9737 - val_loss: 0.1191 - val_accuracy: 0.9727\nEpoch 697/700\n18/18 [==============================] - 0s 27ms/step - loss: 0.1299 - accuracy: 0.9737 - val_loss: 0.1186 - val_accuracy: 0.9727\nEpoch 698/700\n18/18 [==============================] - 0s 16ms/step - loss: 0.1295 - accuracy: 0.9737 - val_loss: 0.1182 - val_accuracy: 0.9727\nEpoch 699/700\n18/18 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9737 - val_loss: 0.1180 - val_accuracy: 0.9727\nEpoch 700/700\n18/18 [==============================] - 0s 18ms/step - loss: 0.1288 - accuracy: 0.9737 - val_loss: 0.1177 - val_accuracy: 0.9727\n","output_type":"stream"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f0cac370358>"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"XyT2BG3nRVb9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"21284d14-9b58-4e3c-b8df-bf9b168abbd1","cell_id":"00014-b26f4d76-ebaf-4aa7-95e9-038ea8c58ff0"},"source":"model.evaluate(X_test, y_test)","execution_count":18,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 0s 12ms/step - loss: 0.1177 - accuracy: 0.9727\n","output_type":"stream"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"[0.11768496781587601, 0.9727272987365723]"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"nsDPAElARkAT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"b0f4d943-e0d6-4a3f-a2e5-0415d67b1633","cell_id":"00015-6fec8109-a43c-4d8c-bbbe-048b3d2c6971"},"source":"test_data.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":5,"column_count":4,"columns":[{"name":"VWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-3.7181,"max":5.504,"histogram":[{"bin_start":-3.7181,"bin_end":-2.79589,"count":1},{"bin_start":-2.79589,"bin_end":-1.8736800000000002,"count":0},{"bin_start":-1.8736800000000002,"bin_end":-0.95147,"count":0},{"bin_start":-0.95147,"bin_end":-0.029260000000000286,"count":1},{"bin_start":-0.029260000000000286,"bin_end":0.8929499999999995,"count":0},{"bin_start":0.8929499999999995,"bin_end":1.81516,"count":1},{"bin_start":1.81516,"bin_end":2.73737,"count":0},{"bin_start":2.73737,"bin_end":3.6595799999999996,"count":0},{"bin_start":3.6595799999999996,"bin_end":4.58179,"count":0},{"bin_start":4.58179,"bin_end":5.504,"count":2}]}},{"name":"SWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-8.5089,"max":10.3671,"histogram":[{"bin_start":-8.5089,"bin_end":-6.621300000000001,"count":1},{"bin_start":-6.621300000000001,"bin_end":-4.733700000000001,"count":0},{"bin_start":-4.733700000000001,"bin_end":-2.8461,"count":0},{"bin_start":-2.8461,"bin_end":-0.9584999999999999,"count":0},{"bin_start":-0.9584999999999999,"bin_end":0.9291,"count":1},{"bin_start":0.9291,"bin_end":2.816700000000001,"count":1},{"bin_start":2.816700000000001,"bin_end":4.7043,"count":0},{"bin_start":4.7043,"bin_end":6.591900000000001,"count":0},{"bin_start":6.591900000000001,"bin_end":8.479500000000002,"count":0},{"bin_start":8.479500000000002,"bin_end":10.3671,"count":2}]}},{"name":"CWTI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-4.413,"max":12.363,"histogram":[{"bin_start":-4.413,"bin_end":-2.7354000000000003,"count":1},{"bin_start":-2.7354000000000003,"bin_end":-1.0578000000000003,"count":1},{"bin_start":-1.0578000000000003,"bin_end":0.6197999999999997,"count":2},{"bin_start":0.6197999999999997,"bin_end":2.2973999999999997,"count":0},{"bin_start":2.2973999999999997,"bin_end":3.9749999999999996,"count":0},{"bin_start":3.9749999999999996,"bin_end":5.6526,"count":0},{"bin_start":5.6526,"bin_end":7.3302,"count":0},{"bin_start":7.3302,"bin_end":9.0078,"count":0},{"bin_start":9.0078,"bin_end":10.6854,"count":0},{"bin_start":10.6854,"bin_end":12.363,"count":1}]}},{"name":"EI","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":-4.0211,"max":1.6543,"histogram":[{"bin_start":-4.0211,"bin_end":-3.4535599999999995,"count":1},{"bin_start":-3.4535599999999995,"bin_end":-2.88602,"count":0},{"bin_start":-2.88602,"bin_end":-2.31848,"count":0},{"bin_start":-2.31848,"bin_end":-1.75094,"count":0},{"bin_start":-1.75094,"bin_end":-1.1833999999999998,"count":1},{"bin_start":-1.1833999999999998,"bin_end":-0.6158600000000001,"count":1},{"bin_start":-0.6158600000000001,"bin_end":-0.04832000000000036,"count":0},{"bin_start":-0.04832000000000036,"bin_end":0.5192199999999998,"count":0},{"bin_start":0.5192199999999998,"bin_end":1.08676,"count":1},{"bin_start":1.08676,"bin_end":1.6543,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"VWTI":-0.40804,"SWTI":0.54214,"CWTI":-0.52725,"EI":0.6586,"_deepnote_index_column":0},{"VWTI":-3.7181,"SWTI":-8.5089,"CWTI":12.363,"EI":-0.95518,"_deepnote_index_column":1},{"VWTI":5.504,"SWTI":10.3671,"CWTI":-4.413,"EI":-4.0211,"_deepnote_index_column":2},{"VWTI":1.6849,"SWTI":8.7489,"CWTI":-1.2641,"EI":-1.3858,"_deepnote_index_column":3},{"VWTI":4.7432,"SWTI":2.1086,"CWTI":0.1368,"EI":1.6543,"_deepnote_index_column":4}],"rows_bottom":null},"text/plain":"      VWTI      SWTI      CWTI       EI\n0 -0.40804   0.54214  -0.52725  0.65860\n1 -3.71810  -8.50890  12.36300 -0.95518\n2  5.50400  10.36710  -4.41300 -4.02110\n3  1.68490   8.74890  -1.26410 -1.38580\n4  4.74320   2.10860   0.13680  1.65430","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VWTI</th>\n      <th>SWTI</th>\n      <th>CWTI</th>\n      <th>EI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.40804</td>\n      <td>0.54214</td>\n      <td>-0.52725</td>\n      <td>0.65860</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-3.71810</td>\n      <td>-8.50890</td>\n      <td>12.36300</td>\n      <td>-0.95518</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.50400</td>\n      <td>10.36710</td>\n      <td>-4.41300</td>\n      <td>-4.02110</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.68490</td>\n      <td>8.74890</td>\n      <td>-1.26410</td>\n      <td>-1.38580</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.74320</td>\n      <td>2.10860</td>\n      <td>0.13680</td>\n      <td>1.65430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"RUXDj1WqSQfG","colab_type":"code","colab":{},"cell_id":"00016-1fdba506-9958-47ce-bb13-bf78cbe70efd"},"source":"prediction = model.predict(test_data)","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"NL8aQawOYPXb","colab_type":"code","colab":{},"cell_id":"00017-dbfbfdb3-e1e5-4b47-a5c1-e17a28e5c6c3"},"source":"predictions =[1 if x >=0.5 else 0 for x in prediction]","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXL5XJDGSV3y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":16},"outputId":"0d30c5aa-7dce-4252-d652-3c97403e3d48","cell_id":"00018-25d9f0c6-ef58-4095-8d13-7a2140905bd1"},"source":"# To create Dataframe of predicted value with particular respective index\nres = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\nres.index = test_data.index # its important for comparison. Here \"test_new\" is your new test dataset\nres.columns = [\"prediction\"]\n \n# To download the csv file locally\n#from google.colab import files\nres.to_csv('prediction_results.csv')         \n#files.download('prediction_results.csv')","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0doCqKFySlAv","colab_type":"code","colab":{},"cell_id":"00019-1ff46273-3402-4fb9-80dc-bda771888008"},"source":"","outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment1.ipynb","provenance":[],"authorship_tag":"ABX9TyOjHcQtKugvYIgvlaHVc4mi","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","deepnote_notebook_id":"a71abcbe-b7ab-445d-a8b7-e11b55f89282","deepnote_execution_queue":[]}}